---
title: "Test"
author: "Kevin Glass"
date: "`r Sys.Date()`"
output: pdf_document
---

---
title           : "Distributions and Their Uses"
author          : "Kevin Glass"
date            : "`r Sys.Date()`"
output          : pdf_document

header-includes :
  - \usepackage{wrapfig}
  - \usepackage{caption}
  - \definecolor{adablue}{html}{00bfb2}
  - \captionsetup[figure]{font = footnotesize}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Simulation setup

### Constants

```{r constants, echo=FALSE, message=FALSE, results = 'hide'}
options(scipen = 999)
options(digits = 3)

# Verify the simulation data is formatted as a list of n matrices
VERIFY_SOURCE_FILE = FALSE    # store to file
VERIFY_SOURCE_SCR  = FALSE    # print to screen
RUN_SIM_VERIFY     = FALSE    # run verification tests

# Verify the mean column data is stored as a list of lists.
VERIFY_MEAN_DISTRIB_FILE  = FALSE
VERIFY_MEAN_DISTRIB_SCR   = FALSE
RUN_VERIFY_MEAN_DISTRIB   = FALSE

# Verify the mean distribution images
VERIFY_MEAN_DIST_IMG      = FALSE
VERIFY_MEAN_DIST_IMG_FILE = FALSE
RUN_MEAN_DIST_IMG         = FALSE

# Verify the simulation data
VERIFY_SAMPLE_STATS_FILE  = FALSE
VERIFY_SAMPLE_STATS_SCR   = FALSE
RUN_VERIFY_STATS          = FALSE

# Verify the mean convergence image
VERIFY_CONVERGE_IMG       = FALSE
RUN_VERIFY_CONVERGE_IMG   = FALSE

# Verify the Tooth image
VERIFY_TOOTH_DATA         = FALSE
RUN_VERIFY_TOOTH_DATA     = FALSE

# Verify the TOOTH image
VERIFY_TOOTH_IMG          = FALSE
RUN_VERIFY_TOOTH_IMG      = FALSE

# Verify the convergence table
VERIFY_CONVERGE_TABLE     = FALSE
RUN_VERIFY_CONVERGE_TABLE = FALSE

# Verify the convergence table
VERIFY_TOOTH_SUMMARY      = FALSE
RUN_VERIFY_TOOTH_SUMMARY  = FALSE

# Verify the convergence table
RUN_CALCULATE_AREA_D      = FALSE
VERIFY_CALCULATE_AREA_D   = FALSE

# Verify the convergence table
EXECUTE      = TRUE

library(dplyr)
library(ggplot2)
library(gridExtra)
library(knitr)
library(kableExtra)
library(ggpubr)
library(matrixStats)
library(data.table)
library(sfsmisc)

set.seed(2063)


lambda       <- 0.2
sampleSize   <- 40
mu           <- 1/lambda
sigma        <- 1/lambda
variance     <- sigma^2
sampleSD     <- sigma/sqrt(sampleSize)

if(FALSE)
{
  print("CONSTANTS")
  print(paste0("lambda            = ", lambda))
  print(paste0("sampleSize        = ", sampleSize))
  print(paste0("mu                = ", mu))
  print(paste0("sigma             = ", sigma))
  print(paste0("variance          = ", variance))
  print(paste0("sampleSD          = ", sampleSD))
}

```
<!-- ###################################################################################### -->
<!-- ###################################################################################### -->
<!-- ###################################################################################### -->
<!-- ### Generate Simulation Data -->

```{r generateSampleMeansLists, echo=FALSE}
# 
# generateSampleMeansLists <- function(sampleRepetition)
# {
#   if(RUN_SIM_VERIFY & VERIFY_MEAN_DISTRIB_SCR | FALSE)
#   {
#     print("generateSampleMeansLists: verify inputs")
#     print(paste0("sampleRepetitions = ", sampleRepetition))
#     print(paste0("sampleSize   = ", sampleSize))
#     print(paste0("lambda       = ", lambda))
#   }
# 
#   # ----------------------------------------------------------------------------------
#   simData <- list()
# 
#   for (i in 1:length(sampleRepetition)) {
#     simData[[i]] <- matrix(rexp(sampleRepetition[i]*sampleSize, lambda),
#                                    nrow = sampleSize, ncol = sampleRepetition[i])
#   }
# 
# 
#   # ----------------------------------------------------------------------------------
# 
#   if(RUN_SIM_VERIFY & VERIFY_SOURCE_FILE | FALSE)
#   {
#     print("generateSampleMeansLists: store in simData_#.csv")
#     filename <- paste0("simData_", sampleRepetition[i], ".csv")
#     write.csv(sampleMatrix, filename, row.names=FALSE)
#   }
# 
#   if(RUN_SIM_VERIFY & VERIFY_SOURCE_SCR | FALSE)
#   {
#     print("generateSampleMeansLists: ")
#     print(simData)
#   }
# 
#   return (simData)
# }
# 
# if(RUN_SIM_VERIFY)
# {
#   sampleRepetition  <- c(10, 20, 30, 40)
# 
#   simData <- generateSampleMeansLists(sampleRepetition)
# 
#   print("RUN_SIM_VERIFY: simData")
#   print(simData)
# }

```

<!-- # Part I -->

<!-- ### Generate Mean Distributions -->

```{r generateMeanDist, echo=FALSE}
# 
# generateMeanDist <- function(sampleRepetition, simData)
# {
#   if(VERIFY_MEAN_DISTRIB_SCR | FALSE)
#   {
#     print("generateMeanDist: verify inputs")
#     print(paste0("sampleRepetitions = ", sampleRepetition))
#     print(paste0("lambda            = ", lambda))
#     print(paste0("mu                = ", mu))
#     print(paste0("variance            = ", variance))
#     print(paste0("sampleSD         = ", sampleSD))
#     # print("simData = ")
#     # print(simData)
#     print("Test sim data separately")
#   }
# 
#   # ----------------------------------------------------------------------------------
#   # distributions     <- list()
#   sampleMeansLists <- list()
# 
#   for (i in 1:length(sampleRepetition)) {
#     sampleMeansLists[[i]]   <- colMeans(simData[[i]])
#   }
# # 
# #   transformToN <- function(sample) {
# #     (sample - mu)/sampleSD
# #   }
# # 
# #   for (i in 1:length(sampleRepetition)) {
# #     sampleMeansLists[[i]]   <- lapply(distributions[[i]], transformToN)
# #     sampleMeansLists[[i]]   <- c(unlist(sampleMeansLists[[i]]))
# #   }
#   
#   if(VERIFY_MEAN_DISTRIB_SCR | FALSE)
#   {
#     for (i in 1:length(sampleRepetition)) {
#       # print("distributions = ")
#       # print(distributions[i])
#       print("sampleMeansLists = ")
#       print(sampleMeansLists[i])
#     }
#   }
# 
#   # ----------------------------------------------------------------------------------
# 
#   if(VERIFY_MEAN_DISTRIB_FILE | FALSE)
#   {
#     print("generateMeanDist: store in simData_#.csv")
#     for (i in 1:length(sampleRepetition)) {
#       filename <- paste0("sampleMeansLists_", sampleRepetition[i], ".csv")
#       write.csv(sampleMeansLists[[i]], filename, row.names=FALSE)
#       
#       filename2 <- paste0("distributions_", sampleRepetition[i], ".csv")
#       write.csv(distributions[[i]], filename2, row.names=FALSE)
#     }
#   }
# 
#   if(VERIFY_MEAN_DISTRIB_SCR | FALSE)
#   {
#     print("generateMeanDist: sampleMeansLists")
#     print(sampleMeansLists)
#   }
# 
#   return (sampleMeansLists)
# }
# 
# if(RUN_VERIFY_MEAN_DISTRIB)
# {
#   sampleRepetition  <- c(10, 20, 30, 40)
# 
#   simData           <- generateSampleMeansLists(sampleRepetition)
#   sampleMeansLists <- generateMeanDist(sampleRepetition, simData)
#   # sampleMeansLists <- generateSampleMeansLists(sampleRepetition)
# 
#   print("RUN_VERIFY_MEAN_DISTRIB: sampleMeansLists")
#   print(sampleMeansLists)
# }

```
<!-- ###################################################################################### -->
<!-- ###################################################################################### --> <!-- ###################################################################################### -->


```{r  echo=FALSE}

generateSampleMeansLists <- function(sampleRepetition)
{
  # ----------------------------------------------------------------------------------
  simData <- list()
  sampleMeansLists <- list()

  for (i in 1:length(sampleRepetition)) {
    simData[[i]] <- matrix(rexp(sampleRepetition[i]*sampleSize, lambda),
                                   nrow = sampleSize, ncol = sampleRepetition[i])
    sampleMeansLists[[i]]   <- colMeans(simData[[i]])
  }

  # ----------------------------------------------------------------------------------

  return (sampleMeansLists)
}

```

### Calculate Sample Mean Stats

```{r calculateSampleMeansStats, echo=FALSE}

calculateSampleMeansStats <- function (sampleRepetition, sampleMeansLists, mu, var)
{
  if(VERIFY_SAMPLE_STATS_SCR | FALSE)
  {
    print("calculateSampleMeansStats: verify inputs")
    print(paste0("mu           = ", mu))
    print(paste0("var          = ", var))
    # print("sampleRepetition = ")
    # print(sampleRepetition)
    print("Test sampleRepetition separately")
    # print("sampleMeansLists = ")
    # print(sampleMeansLists)
    print("Test sampleMeansLists separately")
  }

  # -----------------------------------------------------------------------------
  sampleStats <- data.frame(N_obs = integer(), mu = double(), muErr = double(), 
                            variation = double(), varErr = double())
  for (i in 1:length(sampleRepetition)) {
    xbar     <- mean(sampleMeansLists[[i]])
    variance <- var(sampleMeansLists[[i]])

    sampleStats  <- rbind(sampleStats, 
                           c(sampleRepetition[i], xbar, abs((mu - xbar)/xbar),
                             variance, abs((var - variance)/variance)))
  }
  colnames(sampleStats) <- c("NRep", "Mean", "Absolute\nError of\nMean", 
                             "Variance", "Absolute\nError of\nVariance")
  # -----------------------------------------------------------------------------
  
  return (sampleStats)
}

if(RUN_VERIFY_STATS)
{
  lambda       <- 0.2
  sampleSize   <- 40
  mu           <- 1/lambda
  var          <- mu^2/sqrt(sampleSize)
  sampleRepetition  <- c(10, 20, 30, 40)

  simData           <- generateSampleMeansLists(sampleRepetition, sampleSize, lambda)
  sampleMeansLists  <- calcSampleMeansLists(sampleRepetition, simData)
  sampleMeansStats  <- calculateSampleMeansStats(sampleRepetition, sampleMeansLists, mu, var)
  # print("RUN_VERIFY_STATS: sampleMeansStats")
  # print(sampleMeansStats)
}

```

## Images

### Create Gaussian Images

```{r imageDistribution, echo = FALSE, warning = FALSE, fig.dim = c(6, 5)}

imageMeanDistribution <- function(sampleRepetition, sampleMeansLists, binRange)
{
  if(VERIFY_MEAN_DIST_IMG | TRUE)
  {
    print("imageMeanDistribution: verify inputs")
    print(paste0("sampleRepetitions = ", sampleRepetition))
    print(paste0("sampleSize        = ", sampleSize))
    print(paste0("lambda            = ", lambda))
    print(paste0("mu                = ", mu))
    print(paste0("variance          = ", variance))
    print(paste0("sampleSD          = ", sampleSD))
    print("binRange = ")
    print(binRange)
    # print("Test binRange separately")
    # print("sampleMeansLists = ")
    # print(sampleMeansLists)
    print("Test sampleMeansLists separately")
  }
  # -----------------------------------------------------------------------------
  label <- c("a", "b","c","d")
  pltList <- list()

  transformToN <- function(sample) {
    (sample - mu)/sampleSD + mu
    # sample
  }

  for (i in 1:length(sampleRepetition)) {
    frame <- data.frame(pdf = c(unlist(lapply(sampleMeansLists[[i]], transformToN))))

    if(VERIFY_MEAN_DIST_IMG | FALSE)
    {
      print("imageMeanDistribution: frame")
      print(frame)
      print(sampleMeansLists[[i]])
    }

    if(VERIFY_MEAN_DIST_IMG_FILE | FALSE)
    {
      print("generateMeanDist: store in simData_#.csv")
      filename <- paste0("sampleMeansListsIMG_", sampleRepetition[i], ".csv")
      write.csv(sampleMeansLists[[i]], filename, row.names=FALSE)

      filename2 <- paste0("frame", sampleRepetition[i], ".csv")
      write.csv(frame, filename2, row.names=FALSE)
    }

    pltList[[i]] <- ggplot(frame, aes(x = pdf)) +
      stat_function(fun = function (x) dnorm(x, mean =  5, sd = 1),
        color = "#00bfb2", fill = "#00bfb2", geom = "area", alpha = 0.8) +
      geom_density(alpha = 0.3, color = "#000000", fill="#000000")  +
      geom_histogram(aes(y = after_stat(density)), breaks = binRange, 
                     alpha = 0.2, color = "#505050", linewidth = 0.2) +
      geom_vline(aes(xintercept=mean(pdf)), color="#000000", linewidth = 0.5, linetype = 2) +
      geom_vline(aes(xintercept = 0.0), color="#00bfb2", linewidth = 0.5, linetype = 2) +
      geom_hline(yintercept=0, color="#000000", linewidth = 0.5) +
      ggtitle(paste0("Sample Mean with n = ", sampleRepetition[i])) +
      scale_x_continuous(limits = c(-5, 10), "Mean") +
      scale_y_continuous(limits = c(-0.1, 1), "Density")
  }

  #   pltList[[i]] <- ggplot(frame, aes(x = pdf)) +
  #     stat_function(fun = function (x) dnorm(x, mean =  0, sd = 1),
  #       color = "#00bfb2", fill = "#00bfb2", geom = "area", alpha = 0.8) +
  #     geom_density(alpha = 0.3, color = "#000000", fill="#000000")  +
  #     geom_histogram(aes(y = after_stat(density)), breaks = binRange, 
  #                    alpha = 0.2, color = "#505050", linewidth = 0.2) +
  #     geom_vline(aes(xintercept=mean(pdf)), color="#000000", linewidth = 0.5, linetype = 2) +
  #     geom_vline(aes(xintercept = 0.0), color="#00bfb2", linewidth = 0.5, linetype = 2) +
  #     geom_hline(yintercept=0, color="#000000", linewidth = 0.5) +
  #     ggtitle(paste0("Sample Mean with n = ", sampleRepetition[i])) +
  #     scale_x_continuous(limits = c(-5, 5), "Mean") +
  #     scale_y_continuous(limits = c(-0.1, 0.81), "Density")
  # }

  plt <- ggarrange(pltList[[1]], pltList[[2]], pltList[[3]], pltList[[4]],
          labels = label,
          ncol = 2, nrow = 2)

  ggsave(plot = plt, width = 6.0, height = 4.0, dpi = 300,
         filename = "distribution.png")

}

if(RUN_MEAN_DIST_IMG)
{
  sampleRepetition  <- c(10, 20, 30, 1000)
  binRange          <- seq(-3.0, 10.0, by = 0.5)

  simData           <- generateSampleMeansLists(sampleRepetition)
  sampleMeansLists <- generateMeanDist(sampleRepetition, simData)
  imageMeanDistribution(sampleRepetition, sampleMeansLists, binRange)

  print("RUN_MEAN_DIST_IMG: check image")
}

```


### Create Convergence Image

```{r imageConvergencePlot, echo = FALSE, results = 'hide'}
# ```{r smGraph, echo = FALSE, fig.dim = c(4, 2)}

imageConvergencePlot <- function(sampleRepetition, sampleStats)
{
  if(VERIFY_CONVERGE_IMG | FALSE)
  {
    print("calculateSampleMeansStats: verify inputs")
    print(paste0("mu           = ", mu))
    print(paste0("var          = ", var))
    # print("sampleRepetition = ")
    # print(sampleRepetition)
    print("Test sampleRepetition separately")
    print("sampleStats = ")
    print(sampleStats)
    # print("Test sampleStats separately")
  }

  sampleStats <- cbind(sampleStats, OffsetVar = sampleStats$Variance + 5)
  # names(sampleStats) <- c("size", "mean", "variance")

  graphTics   <- c(5, 10, 100, 1000, 10000, 100000, 1000000)

  plt <- ggplot(sampleStats, aes(x = as.numeric(NRep))) +
    geom_hline(yintercept = 5, color="gray", linewidth = 0.5) +
    geom_hline(yintercept = 5.625, color="pink", linewidth = 0.5) +
    geom_line(aes(y=OffsetVar, color='Variance')) +
    geom_line(aes(y=Mean, color='Mean')) +
    scale_x_log10(breaks = graphTics, limits = c(4.9, 1000000.0)) +
    # scale_x_log10(breaks = graphTics, limits = c(0.1, 1000000.0)) +
    scale_y_continuous(limits = c( 4.7, 5.7 ), "Mean",
    sec.axis = sec_axis(~ . -5, name = "Variance")) +
    ggtitle("Sample Mean and Variance") + xlab("Sample Size (log n)") +
    scale_color_manual(
      name='Statistic', breaks=c('Variance', 'Mean'),
      values=c('Mean'='blue', 'Variance'='red')) +
    theme(plot.title = element_text(size = 10, hjust = 0.5),
          axis.title.x = element_text(size = 8),
          axis.title.y = element_text(size = 8),
          axis.text.x = element_text(face="bold", size=6),
          axis.text.y = element_text(face="bold", size=6),
          legend.title = element_text(size = 6),
          legend.text = element_text(size = 6),
          legend.key.size = unit(2, 'mm'),
          legend.position = c(0.85, 0.55))

  ggsave(plot = plt, width = 4.0, height = 2.5, dpi = 300,
         filename = "converge.png")

}

```


## Tables


### generateConvergeTable

```{r generateConvergeTable, echo = FALSE}
generateConvergeTable <- function (sampleMeansStats)
{
  if(VERIFY_CONVERGE_TABLE | FALSE)
  {
    print("imageConvergence: verify inputs")
    print(paste0("sampleMeansStats  = ", sampleMeansStats))
  }

  # -----------------------------------------------------------------------------

  resTable <- knitr::kable(sampleMeansStats, "latex",
    caption = paste0("table"), digits = 3, align = "llll", row.names = TRUE) %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                  full_width = F,
                  # position = "left",
                  font_size = 8) %>%
    column_spec(column=1, width="0.2cm") %>%
    column_spec(column=2, width="1.0cm") %>%
    column_spec(column=3, width="0.7cm") %>%
    column_spec(column=4, width="1.5cm") %>%
    column_spec(column=5, width="1.0cm") %>%
    column_spec(column=6, width="1.5cm") %>%
    kable_classic_2()
  # -----------------------------------------------------------------------------

  return (resTable)

}

if(RUN_VERIFY_CONVERGE_TABLE)
{
  lambda       <- 0.2
  sampleSize   <- 40
  mu           <- 1/lambda
  var          <- mu^2/sqrt(sampleSize)
  sampleRepetition  <- c(10, 100, 1000, 10000, 100000, 1000000)

  simData           <- generateSampleMeansLists(sampleRepetition, sampleSize, lambda)
  sampleMeansLists  <- calcSampleMeansLists(sampleRepetition, simData)
  sampleMeansStats  <- getSampleMeansStats(sampleRepetition, sampleMeansLists, mu, var)
  resTable          <- generateConvergeTable(sampleMeansStats)

  print("RUN_VERIFY_CONVERGE_TABLE: : resTable")
}

```




# Part II

### Teeth data

```{r generateToothData, echo=FALSE}

generateToothData <- function (ToothGrowth)
{
  if(RUN_VERIFY_TOOTH_DATA | FALSE)
  {
    print("generateToothData: verify inputs")
    print("ToothGrowth = ")
    print(ToothGrowth)
  }

  # -----------------------------------------------------------------------------
  allFactor   <- as.factor(paste0(ToothGrowth$supp, "-", ToothGrowth$dose))
  ToothGrowth <- cbind(ToothGrowth, allFactor)
  # -----------------------------------------------------------------------------

  if(VERIFY_TOOTH_DATA & RUN_VERIFY_TOOTH_DATA | FALSE)
  {
    print("generateToothData: output")
    print("ToothGrowth = ")
    print(ToothGrowth)
  }

  return (ToothGrowth)

}

if(RUN_VERIFY_TOOTH_DATA | FALSE)
{
  doses      = c(0.5, 1.0, 2.0) # mg/day
  supplement = c("OJ", "AA")    # supplement of AA, OJ - Orange Juice, AA - Ascorbic Acid

  nPigs    <- 60
  nLength  <- nPigs/(length(doses)*length(supplement))
  nBins    <- nPigs/nLength
  # bw       <- c(3, 3, 4, 3, 3, 4)

  ToothGrowth <- generateToothData(ToothGrowth)
  print("RUN_VERIFY_TOOTH_DATA: ToothGrowth data")
  print(ToothGrowth)
}


```

### generateToothImage

<!-- , results = 'hide' -->

```{r echo = FALSE, warning = FALSE, fig.dim = c(8, 4)}

generateToothImage <- function (ToothGrowth)
{
  if(VERIFY_TOOTH_IMG | FALSE)
  {
    print("generateToothImage: verify inputs")
    print("ToothGrowth = ")
    print(ToothGrowth)
  }

  # -----------------------------------------------------------------------------
ToothGrowth$dotColor <- c(rep("blue",10),
                          rep("green",10),
                          rep("orange",10),
                          rep("purple",10),
                          rep("yellow",10),
                          rep("red",10))

plt <- ggplot(ToothGrowth, aes(x = allFactor, y = len)) +
  geom_boxplot() +
  geom_dotplot(binaxis='y',
               stackdir='center',
               dotsize = 0.5,
               fill = ToothGrowth$dotColor) +
  labs(title="Effect of Vitamin C on Tooth Growth",
       subtitle="Supplement and Dosage",
       caption="Source: C. I. Bliss (1952). The Statistics of Bioassay. Academic Press.",
       x="Supplement (OJ, VC), Dosage(0.5, 1.0, 2.0)",
       y="Tooth Length")


ggsave(plot = plt, width = 4.0, height = 3.5, dpi = 300,
       filename = "teeth.png")
  # -----------------------------------------------------------------------------

}

if(RUN_VERIFY_TOOTH_IMG)
{
  ToothGrowth <- generateToothData(ToothGrowth)
  generateToothImage(ToothGrowth)
  print("RUN_VERIFY_TOOTH_IMG: check image")
}

```



```{r teethData, echo=FALSE}

# Now in the second portion of the project, we're going to analyze the ToothGrowth data in the R datasets package.
# Load the ToothGrowth data and perform some basic exploratory data analyses

# Provide a basic summary of the data.

# Use confidence intervals and/or hypothesis tests to compare tooth growth by supp and dose. (Only use the techniques from class, even if there's other approaches worth considering)

# State your conclusions and the assumptions needed for your conclusions.

# The response is the length of odontoblasts (cells responsible for tooth
# growth) in 60 guinea pigs. Each animal received one of three dose levels of
# vitamin C (0.5, 1, and 2 mg/day) by one of two delivery methods, orange juice
# or ascorbic acid (a form of vitamin C and coded as AA).
# https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/ToothGrowth

```


# Execute
```{r execute, echo = FALSE}

if(EXECUTE & TRUE)
{
  mu           <- 1/lambda
  var          <- mu^2/sqrt(sampleSize)

  # histogram plots
  sampleRepetition  <- c(10, 30, 40, 1000)
  binRange          <- seq(2.0, 9.0, by = 0.25)
  sampleMeansLists <- generateSampleMeansLists(sampleRepetition)
  imageMeanDistribution(sampleRepetition, sampleMeansLists, binRange)

  # convergence plot
  sampleRepetition <- c(10, 20, 30, 40, 100, 1000, 10000, 100000, 1000000)

  
  sampleMeansLists <- generateSampleMeansLists(sampleRepetition)
  sampleMeansStats <- calculateSampleMeansStats(sampleRepetition, sampleMeansLists, mu, var)
  # sampleStats      <- calculateSampleMeansStats(sampleRepetition, sampleMeansLists)
  imageConvergencePlot(sampleRepetition, sampleMeansStats)

  resTable <- generateConvergeTable(sampleMeansStats)
  
  # sampleMeansLists <- calcSampleMeansLists(sampleRepetition, simData)
  # sampleMeansStats  <- getSampleMeansStats(sampleRepetition, sampleMeansLists, mu, var)
  # resTable          <- generateConvergeTable(sampleMeansStats)

  # tooth plot
  # ToothGrowth <- generateToothData(ToothGrowth)
  # generateToothImage(ToothGrowth)
}

```

# --------------------------------
\newpage
# Overview

Part I of this project will produce a set of simulations designed to show the validity of the Central Limit Theorem. Part II will characterize the R "ToothGrowth" data set [@ToothGrowth] using statistical techniques present by the Johns Hopkins Statistical Inference Online course [@JHU].

# Part 1 : Simulating the Central Limit Theorem

The objective of Part I is to demonstrate the validity of the Central Limit Theorem (CLT). The CLT "states the following. Let $X_1, X_2, X_3, ..., X_n$ denote a random sample of $n$ independent observations from a population with overall expected value (average) $\mu$ and a finite variance $\sigma^2$, and let $\bar{X_n}$ denote the sample mean of that sample (which is itself a random variable). Then the limit as $n \to \infty$ of the distribution of $\frac {\bar {X_n} - \mu}{\sigma_{\bar X_n}}$, where $\sigma_{\bar X_n} = \sigma/\sqrt{n}$ [@wikipedia]." In other words, the distribution of sample means will approach $N(0,1)$ as the number of samples increases, regardless of the distribution of the random values.

To demonstrate the validity the CLT, the document code generate two images. The first image is a set of four plots showing the sample mean distribution with sample sizes of 10, 30, 40, and 1000. The second image shows the mean and variance values for sample mean distributions with sample repetitions of 10, 20, 30, 40, 100, 1000, 10000, 100000, and 1000000.

### Generate Sample Means

The first step in the generation of both images is the generation of samples means lists. The $\textbf{\textit{generateSampleMeansLists}}$ function is responsible for the generation of the random values from the exponential mean and converting those values to the sample means list. Given the sample repetitions set $\{10, 30, 40, 1000\}$, the simulation will generate four matrices of sizes $40 \times 10$, $40 \times 30$, $40 \times 40$, and $40 \times 1000$. For each matrix, the function computes the mean of each column and stores the means in a list.

The $\textit{sampleMeansLists}$ contain the cleaned raw data.

### Create Sample Means Distribution Plots

\begin{wrapfigure}{r}{0.5\textwidth}
  \centering
    \includegraphics[width=\linewidth]{distribution.png}
    \label{label}{Figure 1 a-d}
\end{wrapfigure}

To demonstrate the effect of the CLT on the sample means, the document code generates an image using the $\textbf{\textit{imageMeanDistribution}}$ function. The image consists of four graphs for each of the sample means distributions stored in $\textit{sampleMeansLists}$. Figure 1 (a-d) are the plots for repeat values of n=10, 30, 40, and 1000.

Before the creating the graphs, the document code converts the sample means distribution to a standard normal normal using the z-score transformation (eqn1).

\begin{equation}
\frac {\bar {X_n} - \mu}{\sigma_{\bar X_n}} =  \frac {X_n - 1/\lambda} {\sigma_{40}} =  \frac {\bar {X_n} - 5} {\sigma_{40}}.
\end{equation}

The distribution associated by the transformed sample means should approach a standard normal distribution as the value n increases. To demonstrate the visual similarity between the distributions, it is only necessary to compare the size and shape of both.

Figure 1 a-d compares the distributions by overlaying the $\textcolor{red}sample means distribution in black} and the $\textcolor{red}standard normal distribution in blue}. The graph also includes the histogram created by the corresponding $\textcolor{red}sample means distribution as a set of gray bars} and two dashed lines. $\textcolor{red}{The black line is the mean of the sample means distribution}.

Based on the following observations, the graphs verify that as the number of repetitions increases, the sample means distribution approaches the standard normal distribution. 

1) The area of blue shading and the area of black shading decreases as the number of repetitions increases, 
2) the shape sample means approaches the shape of the standard normal as the number of repetitions increases,
3) the size of the sample means distribution approaches the size of the standard noraml distribution as the number of repetitions increases.

### Quantitative Comparison of Sample Means and Standard Normal Distributions
<!-- \begin{wrapfigure}{l}{0.5\textwidth} -->
<!--   \centering -->
<!--     \includegraphics[width=\linewidth]{converge.png} -->
<!-- \end{wrapfigure} -->

Figure 1 visually compares the sample means distribution to the standard normal distribution. As an added layer of validation, Table 1 show the convergence the sample means to the standard normal distribution quantitatively. 


```{r printTable, echo = FALSE}
resTable
```




<!-- \begin{wrapfigure}{r}{0.5\textwidth} -->
<!--   \centering -->
<!--     \includegraphics[width=\linewidth]{teeth.png} -->
<!-- \end{wrapfigure} -->

<!-- the central limit theorem (CLT) establishes that, in many situations, for independent and identically distributed random variables, the sampling distribution of the standardized sample mean tends towards the standard normal distribution even if the original variables themselves are not normally distributed., which states, "in many situations, for independent and identically distributed random variables, the sampling distribution of the standardized sample mean tends towards the standard normal distribution even if the original variables themselves are not normally distributed[@scribbr]." -->



<!-- that the mean of a large number of samples taken from a distribution will approximate an normal distribution. The point of this demonstration is to validate the Central Limit Theorem, which says "that the sampling distribution of the mean will always follow a normal distribution when the sample size is sufficiently large [@scribbr]."  -->

In this case the code will select values from an exponential distribution,

\begin{equation}
f(x) = \bigg\{
  \begin{array}{ c l }
    \lambda e^{-\lambda x} & \quad \textrm{if } x \geq 0 \\
    0                 & \quad \textrm{if } x < 0
  \end{array}
\end{equation}

<!-- with $\lambda = 0.2$. x`The mean and variance of the exponential distribution are $1/lambda$ and $1/\lamda^2$ respectively. -->

## Exponential Distribution Simulation

<!-- To simulate this behavior, the simulation code will select a sample forty floating point values from the exponential distribution, and repeat the process $n$ times to create a list of $n$ random values. As the value of $n$ increases, the mean and variance of the  -->


<!-- with each the simulation must set a value for the number of objects selected from the distribution, i.e., $\textbf{a sample}$. To determine the sample distribution, the simulation must be repeated several times, and the mean of each sample is stored as part of the $\textbf{sample mean}$. -->

<!-- The simulation will generate $\textbf{forty}$ floating point objects from the exponential distribution, and store the mean in a $\textbf{sample distribution list}$. This process will be repeated $n$ times, making a list of $n$ values, each stored in the sample mean distribution list. The simulation will compute the corresponding mean and variance from each sample distribution list. -->

<!-- The objective of Part I is to show that the distribution of the sample mean generated by a large number of samples will produce an approximately normal distribution. In this case, a simulation will create a sample of forty objects from an exponential distribution with $\lambda = 0.2$, and repeat process between 10 and 10,000,000 times. The number of repeats is determined by the purpose of the simulation. -->

<!-- For each sample, the simulation will calculate and store the sample mean. These values are stored for analysis. -->


## #########################




Part 1 is an analysis of the CLT using a simulation of a non-Gaussian distribution. Each simulation will consist of $n$ samples, and each sample will consist of forty observation taken from an exponential distribution . The project will run the simulation several times each using a different value of $n$. 

For each sample, the program will record the mean and standard values to construct a distribution of the sample means. If the CLT is correct, then the expected result should be a Gaussian distribution with a mean and standard deviation of the rate constant used in the exponential distribution.

## Simulation description

### Exponential distribution

The $\textbf{Exponential Probability Distribution (EPD)}$ with rate constant $\lambda$ is 

where $\frac{1} {\lambda}$ is the rate constant of the distribution. Based on the Johns Hopkins University Statistical Inference Course Project [@JHU-course] the the mean and standard deviation equal $\frac{1} {\lambda}$. A proof for the mean found in The Book of Statistical Proofs [@bookStatProofs-mean] and the variance in [@bookStatProofs-var], keeping in mind that $var = \sigma^2$.

#### ==============


### Central limit theorem
The $\textbf{Central Limit Theorem (CLT)}$ "establishes that, in many situations, for independent and identically distributed random variables, the sampling distribution of the standardized sample mean tends towards the standard normal distribution even if the original variables themselves are not normally distributed.[@wikipedia]" By applying the CLT to the exponential distribution, the program  will show the accuracy of theorem based on the known values of the distribution. 

#### ==============

"The central limit theorem says that the sampling distribution of the mean will always follow a normal distribution when the sample size is sufficiently large. This sampling distribution of the mean isn’t normally distributed because its sample size isn’t sufficiently large.[@scribbr]"


To demonstrate how the Central Limit Theorm (CLT) predicts the distribution and parameters for equation 1. To show this, the simulation will generate forty sets of exponential random numbers for each member of the variable $\textit{SampleSize}$. The simulation will calculate the mean for the forty distributions generated for each sample size.



## Simulation

The simulation is designed to mimic the CLT by generating random values from a exponential distribution with $\lambda = 0.2$. Each selection 


#### ==============

The simulations were run four times with 10, 30, 40, and 1000 repetions for of each sample respectively. The resulting sample means were collected as a list then plotted as a bar graph. In addition to the bar graph, the plot also included a density function plot, a Gaussian density plot with N($1/lambda$, $1/lambda$), and a vertical line at the mean of the sample distrbution. The plots are shown in \@ref{fig:figs}.

The simulation mimics sampling from an exponentially distributed population. Each sample consists of forty values collected by invoking the $\textbf{\textit{rexp}}$ function, and the sample collection is repeated $n$ times. The resulting data set is stored in a matrix, and the distribution of the sample means is found by calculating the mean of each column of the matrix. The collection of sample means is used to generate a $\textit{probability density fuction}$, and to produce the mean and variance of the distribution.

<!-- FIGURE ZZZZ(a-d) show sample distributions with repeat values of 10, 30, 40, and 1000. The distribution data is sorted into contiguous intervals.^[\[2.5, 2.75), \[2.75, 3), \[3, 3.25), \[3.25, 3.5), \[3.5, 3.75), \[3.75, 4), \[4, 4.25), \[4.25, 4.5), \[4.5, 4.75), \[4.75, 5), \[5, 5.25), \[5.25, 5.5), \[5.5, 5.75), \[5.75, 6), \[6, 6.25), \[6.25, 6.5), \[6.5, 6.75), \[6.75, 7), \[7, 7.25), \[7.25, 7.5)] Each value in the sample distribution is binned into on  -->

The simulation mimics the CLT by repeatedly selecting a sample with a fixed number of "observations" from an exponential distribution with $\lambda = 0.2$. The simulations were run four times with 10, 30, 40, and 1000 repetions for of each sample respectively. The resulting sample means were collected as a list then plotted as a bar graph. In addition to the bar graph, the plot also included a density function plot, a Gaussian density plot with N($1/lambda$, $1/lambda$), and a vertical line at the mean of the sample distrbution. The plots are shown in \@ref{fig:figs}.

### Sample distributions
<!-- #  -->
<!-- # ```{r fig.align = 'left', fig.cap= '\\label{fig:figs}Caption', echo=F, out.width='40%'} -->
<!-- # d -->

<!-- ```{r fig.align="left",  out.width = "50%"} -->

<!--  # knitr::include_graphics("distribution.png") -->

<!-- ``` -->








<!-- The standard normal distribution, is -->

<!-- \begin{equation} -->
<!-- Z = \frac {X - \mu}{\sigma} \sim N (0, 1), -->
<!-- \end{equation} -->

<!-- where $X$ is random value chosen from $N (0, 1)$, $\mu$ is the mean of the distribution  and $\sigma$ is the standard deviation. In plain language, $Z$ is the number of standard deviations between $\mu$ and $X$. -->

<!-- The standard deviation of a sample distribution is given as $\sigma / \sqrt n$, where $\sigma$ it standard deviation of the sample distribution, and $n$ is the sample size. Using equation 2 and the EPD parameters, the CLT predicts the distribution of the sample mean is  -->

<!-- \begin{equation} -->
<!-- pdf = \frac {\bar X_n - \mu}{\sigma / \sqrt n} = \frac {\sqrt n(\bar X_n - 1/\lambda)}{1/\lambda } . -->
<!-- \end{equation} -->

<!-- Given $\lambda = 0.2$, the theoretical mean $\mu = 1/\lambda = 5.0$, and the theoretical variation $var = (1/\lambda^2) = 25.0$, the Gaussian predicted by the CLT is  -->

<!-- \begin{equation} -->
<!-- pdf = \frac {\bar X_n - 5.0}{5.0 / \sqrt n} = \frac {\sqrt n(\bar X_n - 5.0)}{5.0 } . -->
<!-- \end{equation} -->








The purpose of this project is two fold. The first is to demonstrate the validity of the Central Limit Theorem (CLT) and second is to apply statistical analysis methods to characterize the R "ToothGrowth" data set [@ToothGrowth]. The CLT asserts that the sampling distribution of the mean will always follow a normal distribution when the sample size is sufficiently large [@scribbr]."

<!-- To demonstrate the validity of the CLT using the exponential distribution, the simulation will sample the distribution with four sample sizes (10, 20, 30, and 1000). The second part of the project will use the R ToothGrowth [] data set to demonstrate various analysis methods. -->


<!-- samples of size $m$ from some non-Gaussian distributions,  with of sample means will approach the Gaussian distribution $N (1/\lambda, 1/\lambda)$ as the number of samples increase. To verify this aspect of the CLT, the program generates a four sets of sample means using the exponential distribution with $mean = 5.0$ and $variance = 25$. Each set   -->




To show how the sample distribution changes with the number of repetitions, the program will process the simulation using a set of repeat values. For example, to show the convergence of the sample mean and variance to the theoretical values, is shown using 


simulations repeats in the set the sample mean and variance use the set {10, 20, 30, 40, 100, 1000, 10000, 100000, 1000000, 10000000} to generate ten pairs of means and variances. The


"The central limit theorem says that the sampling distribution of the mean will always follow a normal distribution when the sample size is sufficiently large. This sampling distribution of the mean isn’t normally distributed because its sample size isn’t sufficiently large.[@scribbr]"


To demonstrate how the Central Limit Theorm (CLT) predicts the distribution and parameters for equation 1. To show this, the simulation will generate forty sets of exponential random numbers for each member of the variable $\textit{SampleSize}$. The simulation will calculate the mean for the forty distributions generated for each sample size.

After calculating the mean and variance for each sample size, the simulation will generate images showing the convergence of both the sample mean and variance as $n \to \infty$. Additionally, the code with generate four plots with $n = 2, 10, 30, 40$ to show the convergence of the sample distribution to a Gaussian distribution. 
The specific steps are:

1. Loop through the $\textit{SampleSize}$ list to get the next sample size, $n$
  + Generate an $n \times nSamples$ matrix and populate it with random variables from the exponential distribution. 
  + Calculate the mean value of each column of the matrix i.e., the sample means, and store the resulting values in the $meanColMatrix$. Each column is a distribution of sample means for a given $n$.
  +  Continue looping
2. Loop through the each column of the $meanColMatrix$
  + Calculate the mean and standard deviation of each column
  + Bind a list with the sample size $n$, and the mean and variance for the $meanColMatrix$ to the $sampleStats$ data frame.
  + Continue looping

## Results













3. Generate Figure 1. This figure is a plot of the sample mean and variance versus the number of samples. The blue line in Figure 1 is the mean of sample mean, and it shows that as $n$ gets larger, it converges the the expected mean $1/\lambda = 5.0$. Figure 1 also represents the change in variance of the sample mean with respect to $n$. The expected variance of the sample distribution

\begin{equation}
Var(X) = \frac{\sigma^2}{n} = \bigg ( \frac {1}{\lambda} \bigg)^2 \frac {1} {n} = 25.0/n,
\end{equation}

(see Appendix 1, section ????).






4. Generate Figure 2. 


Show the sample mean and compare it to the theoretical mean of the distribution.
Show how variable the sample is (via variance) and compare it to the theoretical variance of the distribution.
Show that the distribution is approximately normal.
In point 3, focus on the difference between the distribution of a large collection of random exponentials and the distribution of a large collection of averages of 40 exponentials.





<!-- # Preliminaries -->
<!-- **Exponential Distribution** -->

<!-- The exponential distribution is defined by the function -->

<!-- \[f(x) = \bigg\{ -->
<!--   \begin{array}{ c l } -->
<!--     \lambda e^{-\lambda x} & \quad \textrm{if } x \geq 0 \\ -->
<!--     0                 & \quad \textrm{if } x < 0 -->
<!--   \end{array}\] -->

<!-- where the rate parameter $\lambda$ is the mean number of events over a given time period^[https://en.wikipedia.org/wiki/Exponential_distribution]. The of mean and standard deviations of the exponential distribution are $1/\lambda$ and the variation is $1/\lambda^2$. Derivations for the mean^[https://statproofbook.github.io/P/exp-mean.html] and variance^[https://statproofbook.github.io/P/exp-var.html] can be found in \textbf{The Book of Statistical Proofs}.  -->

**Central Limit Theorem**

<!-- The Central Limit Theorem (CLT) says the mean of sample means of size n will approach the population mean as $n \to \infty$. It also states that the standard deviation of the sample means $\sigma/\sqrt n$ will approach zero as $n \to \infty$ where $\sigma$ is the population mean. It also shows as $n \to \infty$ the sample distribution will approach a normal distribution $N(\mu, \sigma/\sqrt n)$. -->

<!-- # Project 6, part 1: The Exponential Distribution -->
<!-- The goal of this section is to demonstrate the validity of the Central Limit Theorem with respect the exponential distribution. It entails performing several simulations of an exponential distribution to demonstrate the convergence of sample means and the standard error to their theoretical values. It will also display graphical results to visualize the convergence of the distributions to the normal distribution. -->

<!-- The simulation procedure uses the following steps: -->

<!-- 1. Generate a matrix of random values from an exponential distribution. -->
<!--   - The rate constant for the distribution is $\lambda = 0.2$, number of columns in the matrix is 40. -->
<!--   - The number of rows varies in size to show the impact of the CLT. -->
<!-- 2. Store the first row from each matrix, i.e., the first sample distribution in the matrix. -->
<!-- 3. Calculate the mean of each sample in each matrix. This is the sample distribution. -->
<!-- 4. For each sample distribution, store the sample mean and standard deviation. -->

<!-- ### **The Sample Mean and Standard deviation** -->


<!-- \begin{wrapfigure}{r}{0.3\textwidth} -->
<!--   \centering -->
<!--     \includegraphics[width=\linewidth]{converge.png} -->
<!--   \caption{The plot shows the sample mean (blue) and the sample deviation (red). Note the left scale refers to the sample mean and the right refers to the same deviation.} -->
<!-- \end{wrapfigure} -->

<!-- Before the simulation starts, it will create forty sets of samples for each of the specified sample size set^[the sample sizes are: 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 2000, 3000]. It will then create a $n \times 40$ matrix, where $n$ a specified sample size. Each matrix will be filled with random values from an exponential distribution with rate parameter $\lambda$.  -->

<!-- The simulation will compute the average value for each column in each matrix, which results in a column means for the matrix. The column means are then bound to the columns of second matrix called the $meanColMatrix$. Once all of the column means are collected, the $meanColMatrix$ is a $40 \times 21$ matrix, with the full set of column means for each simulation size.  -->

<!-- Based on the exponential distribution, the CLT predicts the column means will converge to $1/\lambda = 1/0.20 = 5.0$ and the standard deviation will converge to 0 as $n \to \infty$. Figure 1 shows the convergence of both the mean and standard deviations. Table 1 includes some select points to show the convergence quantitatively. -->

```{r, echo = FALSE}
  # knitr::kable(statData)
```

<!-- ### *** Normal distribution *** -->
<!-- \begin{wrapfigure}{r}{0.4\textwidth} -->
<!--   \centering -->
<!--     \includegraphics[width=\linewidth]{distribution.png} -->
<!--   \caption{Histograms of } -->
<!-- \end{wrapfigure} -->

<!-- The third requirement for validating the CLT is the distribution of the sample means must be normal. This paper will use visualization to verify that the sample means becomes more normal as $n \to \infty$. Figure 2 shows four sample means distributions of varying sample sizes, each plot is represented as a bar chart. In addition to the sample distribution, each plot includes an overlay of a normal distributon with $\mu = 5.0$ and $\sigma = 5.0$. The overlays are red, with the exception of Figure 2d, which is green to draw attention to the scale change. -->

<!-- Figure 2a shows the sample distribution of $n = 10$. Visually, the plot is left skewed, and has a wide variation.  -->


```{r, echo = FALSE}
  # knitr::kable(histogramData)
```



<!-- Figure 2a is the distribution of the sample means where $n = 10$.   -->


<!-- # Project 6, Part 2: Tooth Length -->

<!-- \begin{wrapfigure}{r}{0.4\textwidth} -->
<!--   \centering -->
<!--     \includegraphics[width=\linewidth]{teeth.png} -->
<!--   \caption{Plot of pressure against temperature} -->
<!-- \end{wrapfigure} -->

<!-- \lipsum[1-3] -->










## #########################


# Bibliography
<!-- https://stackoverflow.com/questions/68372960/how-to-wrap-text-around-charts-in-a-rmarkdown-knit-to-pdf-document -->

[wikipedia https://en.wikipedia.org/wiki/Exponential_distribution]
[mean https://statproofbook.github.io/P/exp-mean.html]
[variance https://statproofbook.github.io/P/exp-var.html]
[reference lecture notes showing mu = 3.5 for rolling dice]
[scribbr https://www.scribbr.com/statistics/central-limit-theorem/]
[JHU-Course https://www.coursera.org/learn/statistical-inference/home/week/1]
[JHU-Project https://www.coursera.org/learn/statistical-inference/peer/3k8j5/statistical-inference-course-project]

[Crampton, E. W. (1947). The growth of the odontoblast of the incisor teeth as a criterion of vitamin C intake of the guinea pig. The Journal of Nutrition, 33(5), 491--504. 10.1093/jn/33.5.491]

# Appendix 1: Code

### Data generate






# --------------------------------


### Generate Sample Distributions

```{r problem1, echo=FALSE}

# set.seed(101)
# 
# nSamples     <- 40
# lambda       <- 0.2
# mu           <- 1/lambda
# sigma        <- 1/lambda
# var          <- 1/lambda^2
# exponentSampleMatrix <- matrix()
# 
# # Simulate 1,000 samples with 40 observations each
# setSource <- function (sampleSize)
# {
#   meanColMatrix          <- matrix(nrow = 0, ncol = nSamples)
#   
#   # print(paste0("sample len ", length(sampleSize)))
#   # print("meanMat data")
#   # print("sampleSize[i]   mu   sigma")
# 
#   for (i in 1:length(sampleSize)) {
#     
#         #                                    40
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+  nSamples
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
# 
# # MDist   ------------------------------------------------------------------------------> 10z`
# # MDist   ------------------------------------------------------------------------------> 20
# 
#     exponentSampleMatrix <- matrix(rexp(sampleSize[i]*nSamples, lambda), 
#                                    nrow = sampleSize[i], ncol = nSamples)
#           
# 
#     # print("setSource: dims(exponentSampleMatrix)")
#     # print(dim(exponentSampleMatrix))
#     # print("setSource: colMeans(exponentSampleMatrix)")
#     # print(colMeans(exponentSampleMatrix))
#     # print(exponentSampleMatrix)
#     
#     meanColMatrix       <- rbind(meanColMatrix, colMeans(exponentSampleMatrix))
# 
#     filename <- paste0("sampleMatrix", sampleSize[i], ".csv")
#     write.csv(exponentSampleMatrix, filename, row.names=FALSE)
# 
#     filename <- paste0("meanColMatrix", sampleSize[i], ".csv")
#     write.csv(meanColMatrix, filename, row.names=FALSE)
# 
#     mu      <- mean(meanColMatrix[i,])
#     variance   <- var(meanColMatrix[i,])
#     print(paste0(sampleSize[i], "   ", mu, "   ", variance))
#   }
# 
#   return (meanColMatrix)
# }
# 

```

### Generate sample stats

```{r generateSampleStats, echo=FALSE}
# 
# generateSampleStats <- function (sampleSize, meanColMatrix)
# {
#   print("generateSampleStats: meanColMatrix")
#   # print(dim(meanColMatrix))
#   # print(meanColMatrix)
# 
#   sampleStats         <- data.frame()
#   for (i in 1:length(sampleSize)) {
#     # print("generateSampleStats: length(meanColMatrix[i,]")
#     # print(length(meanColMatrix[i,]))
#     # print("generateSampleStats: meanColMatrix[i]")
#     # print(meanColMatrix)
#     sampleStats  <-
#       rbind(sampleStats, list(sampleSize[i], mean(meanColMatrix[i,]), var(meanColMatrix[i,])))
#   }
#   colnames(sampleStats) <- c("Size", "Mean", "Variance")
# 
# print("generateSampleStats: sampleStats")
# # print(sampleStats)
# filename <- paste0("sampleStats", sampleSize[i], ".csv")
# write.csv(sampleStats, filename, row.names = FALSE)
# 
#   return (sampleStats)
# }
# sampleSize   <- c(10, 20, 30, 40)
# # sampleSize   <- c(10, 20, 30, 40, 100, 1000, 10000, 100000, 1000000, 10000000)
# meanColMatrix   <- setSource(sampleSize)
# sampleStats  <- generateSampleStats(sampleSize, meanColMatrix)

```

