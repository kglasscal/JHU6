---
title: "Test"
author: "Kevin Glass"
date: "`r Sys.Date()`"
output: pdf_document
---

---
title           : "Distributions and Their Uses"
author          : "Kevin Glass"
date            : "`r Sys.Date()`"
output          : pdf_document

header-includes :
  - \usepackage{wrapfig}
  - \usepackage{caption}
  - \usepackage{xcolor}
  - \usepackage{xelatex}
  - \captionsetup[figure]{font = footnotesize}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{css, echo=FALSE}
.watch-out {
  background-color: gray;
  border: 3px solid red;
  font-weight: bold;
}
```

## Simulation setup

### Constants

```{r constants, echo=FALSE, message=FALSE, results = 'hide'}
options(scipen = 999)
options(digits = 3)

# Verify the simulation data is formatted as a list of n matrices
VERIFY_SOURCE_FILE = FALSE    # store to file
VERIFY_SOURCE_SCR  = FALSE    # print to screen
RUN_SIM_VERIFY     = FALSE    # run verification tests

# Verify the mean column data is stored as a list of lists.
VERIFY_MEAN_DISTRIB_FILE  = FALSE
VERIFY_MEAN_DISTRIB_SCR   = FALSE
RUN_VERIFY_MEAN_DISTRIB   = FALSE

# Verify the mean distribution images
VERIFY_MEAN_DIST_IMG      = FALSE
VERIFY_MEAN_DIST_IMG_FILE = FALSE
RUN_MEAN_DIST_IMG         = FALSE

# Verify the simulation data
VERIFY_SAMPLE_STATS_FILE  = FALSE
VERIFY_SAMPLE_STATS_SCR   = FALSE
RUN_VERIFY_STATS          = FALSE

# Verify the mean convergence image
VERIFY_CONVERGE_IMG       = FALSE
RUN_VERIFY_CONVERGE_IMG   = FALSE

# Verify the Tooth image
VERIFY_TOOTH_DATA         = FALSE
RUN_VERIFY_TOOTH_DATA     = FALSE

# Verify the TOOTH image
VERIFY_TOOTH_IMG          = FALSE
RUN_VERIFY_TOOTH_IMG      = FALSE

# Verify the convergence table
VERIFY_CONVERGE_TABLE     = FALSE
RUN_VERIFY_CONVERGE_TABLE = FALSE

# Verify the convergence table
VERIFY_TOOTH_SUMMARY      = FALSE
RUN_VERIFY_TOOTH_SUMMARY  = FALSE

# Verify the convergence table
RUN_CALCULATE_AREA_D      = FALSE
VERIFY_CALCULATE_AREA_D   = FALSE

# Verify the convergence table
EXECUTE                   = TRUE

library(dplyr)
library(ggplot2)
library(gridExtra)
library(knitr)
library(kableExtra)
library(ggpubr)
library(matrixStats)
library(data.table)
library(sfsmisc)

set.seed(8523)

LAMBDA       <- 0.2
SAMPLE_SIZE   <- 40
MU           <- 1/LAMBDA
SIGMA        <- 1/LAMBDA
VARIANCE     <- SIGMA^2
SAMPLE_ERR     <- SIGMA/sqrt(SAMPLE_SIZE)
SAMPLE_VAR   <- SAMPLE_ERR^2

if(FALSE)
{
  print("CONSTANTS")
  print(paste0("LAMBDA            = ", LAMBDA))
  print(paste0("SAMPLE_SIZE        = ", SAMPLE_SIZE))
  print(paste0("MU                = ", MU))
  print(paste0("SIGMA             = ", SIGMA))
  print(paste0("VARIANCE          = ", VARIANCE))
  print(paste0("SAMPLE_ERR          = ", SAMPLE_ERR))
}

```


### Generate Exponential Data

```{r generateExponentialData,  echo = FALSE}
generateExponentialData <- function(sample)
{
  simData <- matrix(rexp(sample*SAMPLE_SIZE, LAMBDA), nrow = SAMPLE_SIZE, ncol = sample)
  
  if(VERIFY_SAMPLE_STATS_SCR | FALSE)
  {
    print("generateExponentialData: verify inputs")
    print(paste0("MU           = ", MU))
    print(paste0("var          = ", VARIANCE))
    print(paste0("sample      = ", sample))
    print(paste0("SAMPLE_SIZE   = ", SAMPLE_SIZE))
    print("simData = ")
    print(simData)
    # print("Test simData separately")
  }
  return (simData)
}
```

### Calculate Sample Mean Stats

```{r calculateSampleMeansStats, echo=FALSE}
calculateSampleMeansStats <- function (sampleRepetition)
{
  sampleStats <- data.frame(N_obs = integer(), mu = double(), muErr = double(),
                            variation = double(), varErr = double())

  for (sample in 1:length(sampleRepetition)) {
    simData       <- generateExponentialData(sampleRepetition[[sample]])
    sampleMeans   <- colMeans(simData)
    if(VERIFY_SAMPLE_STATS_SCR | FALSE)
    {
      print("generateSampleMeansLists: verify inputs")
      print(paste0("MU           = ", MU))
      print(paste0("var          = ", VARIANCE))
      print("sampleMeans = ")
      print(sampleMeans)
      # print("Test sampleMeans separately")
      # print("simData = ")
      # print(simData)
      print("Test simData separately")
    }
 
    xbar          <- mean(sampleMeans)
    sig_2         <- var(sampleMeans)

    sampleStats  <- rbind(sampleStats,
                           c(sampleRepetition[sample], xbar, abs((MU - xbar)/xbar),
                             sig_2, abs((SAMPLE_VAR - sig_2)/sig_2)))
  }
  colnames(sampleStats) <- c("NRep", "Mean", "Absolute\nError of\nMean",
                             "Variance", "Absolute\nError of\nVariance")
  # -----------------------------------------------------------------------------

  sampleStats <- cbind(sampleStats, OffsetVar = sampleStats$Variance + 5)

  return (sampleStats)
}

```


## Images

### Base Image

```{r baseImage, echo = FALSE, warning = FALSE}
baseImage <- function(n)
{
  plot <- ggplot() +
    stat_function(fun = dnorm, args = c(mean =  5, sd = 1), n = n,
        color = "#000000", fill = "#000000", geom = "area", alpha = 0.2) +
    stat_function(fun = dexp, args = c(rate =  0.2), n = n,
        color = "#00bfb2", fill = "#00bfb2", geom = "area", alpha = 0.5) +
    ggtitle("Exponential and Normal Distributions") +
    scale_x_continuous(limits = c(0, 10), "Mean") +
    scale_y_continuous(limits = c(-0.1, 0.5), "Density")

  ggsave(plot = plot, width = 6.0, height = 4.0, dpi = 300, filename = "base.png")
}
```

### Convergence Image

```{r convergenceImage, echo = FALSE, results = 'hide'}
convergenceImage <- function(sampleRepetition)
{
  sampleStats <- calculateSampleMeansStats(sampleRepetition)

  if(VERIFY_CONVERGE_IMG | FALSE)
  {
    print("calculateSampleMeansStats: verify inputs")
    print(paste0("MU           = ", MU))
    print(paste0("var          = ", VARIANCE))
    # print("sampleRepetition = ")
    # print(sampleRepetition)
    print("Test sampleRepetition separately")
    print("sampleStats = ")
    print(sampleStats)
    # print("Test sampleStats separately")
  }
  graphTics   <- c(10, 100, 1000, 10000, 100000, 1000000)

  plt <- ggplot(sampleStats, aes(x = as.numeric(NRep))) +
    geom_hline(yintercept = 5, color="#e8a200", linewidth = 0.5, linetype = 2) +
    geom_hline(yintercept = 5.625, color="#099e02", linewidth = 0.5, linetype = 2) +
    geom_line(aes(y=OffsetVar, color='Variance')) +
    geom_line(aes(y=Mean, color='Mean')) +
    scale_x_log10(breaks = graphTics, limits = c(4.9, 1000000.0)) +
    # scale_x_log10(breaks = graphTics, limits = c(0.1, 1000000.0)) +
    scale_y_continuous(limits = c(4.7, 6.0), "Mean",
    sec.axis = sec_axis(~ . -5, name = "Variance")) +
    ggtitle("Sample Mean and Variance") + xlab("Sample Size (log n)") +
    scale_color_manual(
      name='Statistic', breaks=c('Variance', 'Mean'),
      values=c('Mean'='#e8a200', 'Variance'='#099e02')) +
    theme(plot.title = element_text(size = 10, hjust = 0.5),
          axis.title.x = element_text(size = 8),
          axis.title.y = element_text(size = 8),
          axis.text.x = element_text(face="bold", size=6),
          axis.text.y = element_text(face="bold", size=6),
          legend.title = element_text(size = 6),
          legend.text = element_text(size = 6),
          legend.key.size = unit(2, 'mm'),
          legend.position = c(0.85, 0.55))

  ggsave(plot = plt, width = 4.0, height = 2.5, dpi = 300,
         filename = "converge.png")
}

```

### Normal Distribution Images

```{r imageDistribution, echo = FALSE, warning = FALSE, fig.dim = c(6, 5)}
normalDistributionImages <- function(sampleRepetition)
{
  binRange          <- seq(2.0, 9.0, by = 0.25)

  if(VERIFY_MEAN_DIST_IMG | FALSE)
  {
    print("imageNormalDistribution: verify inputs")
    print(paste0("sampleRepetitions = ", sampleRepetition))
    print(paste0("SAMPLE_SIZE        = ", SAMPLE_SIZE))
    print(paste0("LAMBDA            = ", LAMBDA))
    print(paste0("MU                = ", MU))
    print(paste0("VARIANCE          = ", VARIANCE))
    print(paste0("SAMPLE_ERR          = ", SAMPLE_ERR))
    print("binRange = ")
    print(binRange)
    # print("Test binRange separately")
    print("sampleMeansLists = ")
    print(sampleMeansLists)
    # print("Test sampleMeansLists separately")
  }
  # -----------------------------------------------------------------------------
  label <- c("a", "b","c","d")
  pltList <- list()

  transformToN <- function(sample) {
    (sample - MU)/SAMPLE_ERR + MU
  }

  simData  <- list()
  colData  <- list()
  sampleMeans  <- list()
  # sourceData  <- list()

  for (i in 1:length(sampleRepetition)) {
    simData[[i]]   <- generateExponentialData(sampleRepetition[i])
    colData[[i]]   <- colMeans(simData[[i]])
    sampleMeans[[i]] <- data.frame(pdf = c(unlist(lapply(colData[[i]], transformToN))))
    # sourceData[[i]]  <- data.frame(pdf = c(unlist(lapply(simData[[i]], transformToN))))
    
    if(VERIFY_MEAN_DIST_IMG | FALSE)
    {
      print("imageNormalDistribution: sampleMeans")
      print(sampleMeans[[i]])
      # print(sourceData[[i]])
    }

    if(VERIFY_MEAN_DIST_IMG_FILE | FALSE)
    {
      print("generateMeanDist: store in simData_#.csv")
      filename <- paste0("sampleMeansListsIMG_", sampleRepetition[i], ".csv")
      write.csv(sampleMeansLists[[i]], filename, row.names=FALSE)

      filename2 <- paste0("sampleMeans", sampleRepetition[i], ".csv")
      write.csv(sampleMeans, filename2, row.names=FALSE)
    }

    pltList[[i]] <- ggplot(sampleMeans[[i]], aes(x = pdf)) +
      stat_function(fun = function (x) dnorm(x, mean =  5, sd = 1),
        color = "#00bfb2", fill = "#00bfb2", geom = "area", alpha = 0.8) +
      geom_density(alpha = 0.3, color = "#000000", fill="#000000")  +
      geom_histogram(aes(y = after_stat(density)), breaks = binRange,
                     alpha = 0.2, color = "#505050", linewidth = 0.2) +
      geom_vline(aes(xintercept=mean(pdf)), color="#000000", linewidth = 0.5, linetype = 2) +
      geom_vline(aes(xintercept = MU), color="#00bfb2", linewidth = 0.5, linetype = 2) +
      geom_hline(yintercept=0, color="#000000", linewidth = 0.5) +
      ggtitle(paste0("Sample Mean with n = ", sampleRepetition[i])) +
      scale_x_continuous(limits = c(0, 10), "Mean") +
      scale_y_continuous(limits = c(-0.1, 0.8), "Density")
  }

  plt <- ggarrange(pltList[[1]], pltList[[2]], pltList[[3]], pltList[[4]],
          labels = label, ncol = 2, nrow = 2)
  ggsave(plot = plt, width = 6.0, height = 4.0, dpi = 300, filename = "distribution.png")
}

if(RUN_MEAN_DIST_IMG)
{
  sampleRepetition  <- c(10, 20, 30, 1000)
  binRange          <- seq(-3.0, 10.0, by = 0.5)

  simData           <- generateSampleMeansLists(sampleRepetition)
  sampleMeansLists <- generateMeanDist(sampleRepetition, simData)
  imageNormalDistribution(sampleRepetition, sampleMeansLists, binRange)

  print("RUN_MEAN_DIST_IMG: check image")
}

```

## Tables

### generateConvergeTable

```{r generateConvergeTable, echo = FALSE}
generateConvergeTable <- function (sampleRepetition)
{
  sampleStats <- calculateSampleMeansStats(sampleRepetition)

  if(VERIFY_CONVERGE_TABLE | FALSE)
  {
    print("imageConvergence: verify inputs")
    print(paste0("sampleStats  = ", sampleStats))
  }

  # -----------------------------------------------------------------------------

  resTable <- knitr::kable(sampleStats, "latex",
    caption = paste0("table"), digits = 3, align = "llll", row.names = TRUE) %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                  full_width = F,
                  # position = "left",
                  font_size = 8) %>%
    column_spec(column=1, width="0.2cm") %>%
    column_spec(column=2, width="1.0cm") %>%
    column_spec(column=3, width="0.7cm") %>%
    column_spec(column=4, width="1.5cm") %>%
    column_spec(column=5, width="1.0cm") %>%
    column_spec(column=6, width="1.5cm") %>%
    kable_classic_2()
  # -----------------------------------------------------------------------------

  return (resTable)

}

if(RUN_VERIFY_CONVERGE_TABLE)
{
  LAMBDA       <- 0.2
  SAMPLE_SIZE   <- 40
  MU           <- 1/LAMBDA
  var          <- MU^2/sqrt(SAMPLE_SIZE)
  sampleRepetition  <- c(10, 100, 1000, 10000, 100000, 1000000)

  simData           <- generateSampleMeansLists(sampleRepetition, SAMPLE_SIZE, LAMBDA)
  sampleMeansLists  <- calcSampleMeansLists(sampleRepetition, simData)
  sampleMeansStats  <- getSampleMeansStats(sampleRepetition, sampleMeansLists, MU, var)
  resTable          <- generateConvergeTable(sampleMeansStats)

  print("RUN_VERIFY_CONVERGE_TABLE: : resTable")
}

```


# Part II


```{r teethData, echo=FALSE}

# Now in the second portion of the project, we're going to analyze the ToothGrowth data in the R datasets package.
# Load the ToothGrowth data and perform some basic exploratory data analyses

# Provide a basic summary of the data.

# Use confidence intervals and/or hypothesis tests to compare tooth growth by supp and dose. (Only use the techniques from class, even if there's other approaches worth considering)

# State your conclusions and the assumptions needed for your conclusions.

# The response is the length of odontoblasts (cells responsible for tooth
# growth) in 60 guinea pigs. Each animal received one of three dose levels of
# vitamin C (0.5, 1, and 2 mg/day) by one of two delivery methods, orange juice
# or ascorbic acid (a form of vitamin C and coded as AA).
# https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/ToothGrowth

```

### Set Tooth Data

```{r setToothData, echo=FALSE}
setToothData <- function (ToothGrowth)
{
  if(RUN_VERIFY_TOOTH_DATA | FALSE)
  {
    print("setToothData: verify inputs")
    print("ToothGrowth = ")
    print(ToothGrowth)
  }
  if(RUN_VERIFY_TOOTH_DATA | FALSE)
  {
    print("ToothGrowth unique values")
    suppValues <- c(unique(ToothGrowth$supp))
    print(suppValues[2])
    print(class(suppValues))
  }

  columnNames <- unique(paste0(ToothGrowth$supp, '-', ToothGrowth$dose))
  toothDF     <- data.frame(matrix(nrow = 10, ncol = 0))
  for ( i in 1:length(columnNames)) {
    toothDF     <- cbind(toothDF, ToothGrowth[(i - 1) * 10 + 1 : 10, 1])
  }
  colnames(toothDF) <- columnNames
  

  if(VERIFY_TOOTH_DATA & RUN_VERIFY_TOOTH_DATA | TRUE)
  {
    print("setToothData: output")
    # print("ToothGrowth = ")
    # print(ToothGrowth)
    # print(ToothGrowth[1:10,1])
    print("toothDF = ")
    print(toothDF)

    # subtest <- c(unlist(toothDF[1]), unlist(toothDF[2]))
    # print(subtest)
    # print(summary(subtest))
  }

  return (toothDF)

}

if(RUN_VERIFY_TOOTH_DATA | FALSE)
{
  doses      = c(0.5, 1.0, 2.0) # mg/day
  supplement = c("OJ", "AA")    # supplement of AA, OJ - Orange Juice, AA - Ascorbic Acid

  nPigs    <- 60
  nLength  <- nPigs/(length(doses)*length(supplement))
  nBins    <- nPigs/nLength
  # bw       <- c(3, 3, 4, 3, 3, 4)

  ToothGrowth <- setToothData(ToothGrowth)
  print("RUN_VERIFY_TOOTH_DATA: ToothGrowth data")
  print(ToothGrowth)
}
```

### Generate Tooth Image

<!-- , results = 'hide' -->

```{r echo = FALSE, warning = FALSE, fig.dim = c(8, 4)}

generateToothSuppImage <- function (ToothGrowth)
{
  if(VERIFY_TOOTH_IMG | FALSE)
  {
    print("generateToothImage: verify inputs")
    print("ToothGrowth = ")
    print(ToothGrowth)
  }

  ToothGrowth$dotColor <- c(rep("blue",10),
                            rep("green",10),
                            rep("orange",10),
                            rep("purple",10),
                            rep("yellow",10),
                            rep("red",10))
  
  plt <- ggplot(ToothGrowth, aes(x = supp, y = len)) +
    geom_boxplot() +
    geom_dotplot(binaxis='y',
                 stackdir='center',
                 dotsize = 0.7,
                 fill = ToothGrowth$dotColor) +
    labs(title="Effect of Vitamin C on Tooth Growth",
         subtitle="Supplement and Dosage",
         caption="Source: C. I. Bliss (1952). The Statistics of Bioassay. Academic Press.",
         x="Supplement (OJ, VC), Dosage(0.5, 1.0, 2.0)",
         y="Tooth Length")
  
  
  ggsave(plot = plt, width = 4.0, height = 3.5, dpi = 300,
         filename = "tooth-supp.png")
}

### Generate Tooth Image

generateToothImage <- function (ToothGrowth)
{
  if(VERIFY_TOOTH_IMG | FALSE)
  {
    print("generateToothImage: verify inputs")
    print("ToothGrowth = ")
    print(ToothGrowth)
  }

  ToothGrowth$dotColor <- c(rep("blue",10),
                            rep("green",10),
                            rep("orange",10),
                            rep("purple",10),
                            rep("yellow",10),
                            rep("red",10))
  
  plt <- ggplot(ToothGrowth, aes(x = as.factor(dose), y = len)) +
    geom_boxplot() +
    geom_dotplot(binaxis='y',
                 stackdir='center',
                 dotsize = 0.7,
                 fill = ToothGrowth$dotColor) +
    labs(title="Effect of Vitamin C on Tooth Growth",
         subtitle="Supplement and Dosage",
         caption="Source: C. I. Bliss (1952). The Statistics of Bioassay. Academic Press.",
         x="Supplement (OJ, VC), Dosage(0.5, 1.0, 2.0)",
         y="Tooth Length")
  
  
  ggsave(plot = plt, width = 4.0, height = 3.5, dpi = 300,
         filename = "tooth.png")
}

if(RUN_VERIFY_TOOTH_IMG)
{
  ToothGrowth <- setToothData(ToothGrowth)
  generateToothImage(ToothGrowth)
  print("RUN_VERIFY_TOOTH_IMG: check image")
}

```


### Summaries

### Generate Tooth Summaries

```{r generateToothSummaries, echo = TRUE}

 # Hypotheses:
 #  Difference of tooth length do to VC or OJ is zero
 #  Difference between {0.5, 1.0}, {0.5, 2.0},  {1.0, 2.0} are all zero
 # 
 # The number of observations for each sample are the same (supplement = 30, dose = 20)
 # Find the difference in mean, and variance
 # 
 # t.test(father.son$sheight - father.son$fheight)
 # 
 # 

generateToothSummaries <- function(toothDF)
{
  if(VERIFY_TOOTH_SUMMARY | FALSE)
  {
    print("generateToothSummaries: verify inputs")
    print(paste0("ToothGrowth[[1]]  = ", toothDF[1:10,]))
    print(paste0("ToothGrowth  = ", toothDF))
  }

  protocol <- c("OJ v. VC", "0.5 v. 1.0", "0.5 v. 2.0", "1.0 v. 2.0",
                unique(paste0(toothDF$supp, '-', toothDF$dose))
  )
  print(paste0("protocol ", protocol))

  fullSummary <- summary(toothDF)
  dataSet <- list()
  ttest   <- list()

  vc.Data    <- c(unlist(toothDF[[1]]), unlist(toothDF[[2]]), unlist(toothDF[[3]]))
  oj.Data    <- c(unlist(toothDF[[4]]), unlist(toothDF[[5]]), unlist(toothDF[[6]]))
  d.0_5.Data <- c(unlist(toothDF[[1]]), unlist(toothDF[[4]]))
  d.1_0.Data <- c(unlist(toothDF[[2]]), unlist(toothDF[[5]]))
  d.2_0.Data <- c(unlist(toothDF[[3]]), unlist(toothDF[[6]]))
  
  dataSet   <- data.frame(
    statistic     = double(0),
    parameter     = double(0),
    p.value       = double(0),
    conf.int.low  = double(0),
    conf.int.high = double(0),
    estimate.low  = double(0),
    estimate.high = double(0),
    null.value    = integer(0),
    stderr        = double(0),
    alternative   = character(0),
    method        = character(0),
    data.name     = character(0)
  )

  # "two.sided", "less", "greater"
  alternative <- "two.sided"

  ttest[[1]] <- t.test(x = vc.Data, y = oj.Data, alternative = c(alternative),
                   paired = FALSE, var.equal = FALSE)
  ttest[[2]] <- t.test(x = d.0_5.Data, y = d.1_0.Data, alternative = c(alternative),
                       paired = FALSE, var.equal = FALSE)
  ttest[[3]] <- t.test(x = d.0_5.Data, y = d.2_0.Data, alternative = c(alternative),
                       paired = FALSE, var.equal = FALSE)
  ttest[[4]] <- t.test(x = d.1_0.Data, y = d.2_0.Data, alternative = c(alternative),
                       paired = FALSE, var.equal = FALSE)
  
  k = 5
  for (i in 1:5) {
    for (j in (i+1):6) {
      ttest[[k]] <- t.test(x = toothDF[[i]], y = toothDF[[j]], alternative = c(alternative),
                       paired = FALSE, var.equal = FALSE)
      k = k + 1
    }
  }

  # ttest[[5]] <- t.test(x = toothDF[[1]], y = toothDF[[2]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)
  # ttest[[6]] <- t.test(x = toothDF[[1]], y = toothDF[[3]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)
  # ttest[[7]] <- t.test(x = toothDF[[1]], y = toothDF[[4]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)
  # ttest[[8]] <- t.test(x = toothDF[[1]], y = toothDF[[5]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)
  # ttest[[9]] <- t.test(x = toothDF[[1]], y = toothDF[[6]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)
  # ttest[[10]] <- t.test(x = toothDF[[2]], y = toothDF[[3]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)
  # ttest[[11]] <- t.test(x = toothDF[[2]], y = toothDF[[4]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)
  # ttest[[12]] <- t.test(x = toothDF[[2]], y = toothDF[[5]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)
  # ttest[[13]] <- t.test(x = toothDF[[2]], y = toothDF[[6]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)
  # ttest[[14]] <- t.test(x = toothDF[[3]], y = toothDF[[4]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)
  # ttest[[15]] <- t.test(x = toothDF[[3]], y = toothDF[[5]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)
  # ttest[[16]] <- t.test(x = toothDF[[3]], y = toothDF[[6]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)
  # ttest[[17]] <- t.test(x = toothDF[[4]], y = toothDF[[5]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)
  # ttest[[18]] <- t.test(x = toothDF[[4]], y = toothDF[[6]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)
  # ttest[[19]] <- t.test(x = toothDF[[5]], y = toothDF[[6]], alternative = c(alternative),
  #                      paired = FALSE, var.equal = FALSE)

  for (t in ttest) {
    dataSet <- rbind(dataSet, c(
      t[1][[1]], t[2][[1]], t[3][[1]], t[4][[1]][1], t[4][[1]][2], t[5][[1]][1], t[5][[1]][2],
      t[6][[1]], t[7][[1]], t[8][[1]], t[9][[1]], t[10][[1]]))
  }

  colNames  <- c("statistic", "parameter", "p.value", "conf.int.low", "conf.int.high",
                 "estimate.low", "estimate.high", "null.value", "stderr", "alternative",
                 "method", "data.name")

  colnames(dataSet) <- colNames

#   # -----------------------------------------------------------------------------
  if( VERIFY_TOOTH_SUMMARY | FALSE)
  {
    print("supp.T")
    print(ttest)
    print("d0.5_1.0.T")
    print(d0.5_1.0.T)
    print("d0.5_2.0.T")
    print(d0.5_2.0.T)
    print("d1.0_2.0.T")
    print(d1.0_2.0.T)
    print(names(d1.0_2.0.T))
  }

  if( VERIFY_TOOTH_SUMMARY | FALSE)
  {
    print(paste0("supp.T['statistic'][[1]]:   ", supp.T["statistic"][[1]]))
    print(paste0("supp.T['parameter'][[1]]:   ", supp.T["parameter"][[1]]))
    print(paste0("supp.T['p.value']:          ", supp.T["p.value"]))
    print(paste0("supp.T['conf.int'][[1]][1]: ", supp.T["conf.int"][[1]][1]))
    print(paste0("supp.T['conf.int'][[2]][2]: ", supp.T["conf.int"][[1]][2]))
    print(paste0("supp.T['estimate'][[1]][1]: ", supp.T["estimate"][[1]][1]))
    print(paste0("supp.T['estimate'][[1]][2]: ", supp.T["estimate"][[1]][2]))
    print(paste0("supp.T['null.value'][[1]]:  ", supp.T["null.value"][[1]]))
    print(paste0("supp.T['stderr']:           ", supp.T["stderr"]))
    print(paste0("supp.T['alternative']:      ", supp.T["alternative"]))
    print(paste0("supp.T['method']:           ", supp.T["method"]))
    print(paste0("supp.T['data.name']:        ", supp.T["data.name"]))
  }
  if( VERIFY_TOOTH_SUMMARY | TRUE)
  {
    print("dataSet")
    print(dataSet)
  }


  if(VERIFY_TOOTH_SUMMARY | FALSE)
  {
    print("fullSummary")
    print(fullSummary)
  }
}

if(RUN_VERIFY_TOOTH_SUMMARY)
{
  supplement = c("OJ", "AA")    # supplement of AA, OJ - Orange Juice, AA - Ascorbic Acid
  doses      = c(0.5, 1.0, 2.0) # mg/day
  nPigs    <- 60
  nLength  <- nPigs/(length(doses)*length(supplement))
  teeth    <- list()
  
  ToothGrowth <- setToothData(ToothGrowth)
  for (i in 1:6) { 
    start   <- ((i - 1) * nLength) + 1
    finish  <- i * nLength
    teeth[[i]] <- ToothGrowth[start : finish,]
    print("tooth")
    print(teeth[[i]])
  }
  
  generateToothSummaries(ToothGrowth)
}

```

```{r generateSummaryTable, echo = FALSE}
generateSummaryTable <- function (sampleRepetition)
{
  if(VERIFY_CONVERGE_TABLE | FALSE)
  {
    print("imageConvergence: verify inputs")
    print(paste0("sampleStats  = ", sampleStats))
  }

  resTable <- knitr::kable(sampleStats, "latex",
    caption = paste0("table"), digits = 3, align = "llll", row.names = TRUE) %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                  full_width = F,
                  # position = "left",
                  font_size = 8) %>%
    column_spec(column=1, width="0.2cm") %>%
    column_spec(column=2, width="1.0cm") %>%
    column_spec(column=3, width="0.7cm") %>%
    column_spec(column=4, width="1.5cm") %>%
    column_spec(column=5, width="1.0cm") %>%
    column_spec(column=6, width="1.5cm") %>%
    kable_classic_2()
  # -----------------------------------------------------------------------------

  return (resTable)

}

if(RUN_VERIFY_CONVERGE_TABLE)
{
  LAMBDA       <- 0.2
  SAMPLE_SIZE   <- 40
  MU           <- 1/LAMBDA
  var          <- MU^2/sqrt(SAMPLE_SIZE)
  sampleRepetition  <- c(10, 100, 1000, 10000, 100000, 1000000)

  simData           <- generateSampleMeansLists(sampleRepetition, SAMPLE_SIZE, LAMBDA)
  sampleMeansLists  <- calcSampleMeansLists(sampleRepetition, simData)
  sampleMeansStats  <- getSampleMeansStats(sampleRepetition, sampleMeansLists, MU, var)
  resTable          <- generateConvergeTable(sampleMeansStats)

  print("RUN_VERIFY_CONVERGE_TABLE: : resTable")
}

```

# Execute

```{r execute, echo = FALSE}

if(EXECUTE & TRUE)
{
  baseImage(100)

  # sampleRepetition  <- c(10, 20, 30, 40, 100, 1000, 10000, 100000, 1000000)
  # convergenceImage(sampleRepetition)
  # 
  # resTable <- generateConvergeTable(sampleRepetition)
  # 
  # sampleRepetition  <- c(10, 20, 40, 1000)
  # normalDistributionImages(sampleRepetition)


  # tooth plot
  
  # -----------------------------------------------------------------------------
  allFactor   <- as.factor(paste0(ToothGrowth$supp, "-", ToothGrowth$dose))
  ToothGrowth <- cbind(ToothGrowth, allFactor)
  # -----------------------------------------------------------------------------

  # generateToothImage(ToothGrowth)
  # generateToothSuppImage(ToothGrowth)
  
  toothDF <- setToothData(ToothGrowth)
  generateToothSummaries(toothDF)
  
}

```

# --------------------------------
\newpage
# Overview

Part I of this project will produce a set of simulations designed to show the validity of the Central Limit Theorem (CLT). Part II will characterize the R "ToothGrowth" data set [@ToothGrowth] using statistical techniques presented on the Johns Hopkins Statistical Inference Online Course [@JHU].

# Part 1
## Simulating an Exponential Distribution

The simulation uses two probability distribution functions, the exponential and normal distributions. For reference, Figure 1 shows these both of the distributions.  

\begin{wrapfigure}{r}{0.3\textwidth}
  \centering
    \includegraphics[width=\linewidth]{base.png}
\end{wrapfigure}

The goal of the simulation is to establish three points:

1 \textbf{The theoretical mean of the sample means converges to the same mean as the exponential distribution}.

2 \textbf{The theoretical variance of the sample means converges to the same variance as the exponential distribution}.

3 \textbf{The sample means distribution approximates $N(\mu, \sigma^2)$ }.

To address these points, the simulation will produce IIIIII images, and IIIIII tables. These include plots showing the convergence of the sample means to the theoretical mean and variance, and a plot showing the convergence of the sample mean distribution to $N(\mu, \sigma^2)$.

WHAT ARE MU AND SIGMA? [wikipedia https://en.wikipedia.org/wiki/Exponential_distribution]

### $\textbf{Setting up Simulation Data}$

The Central Limit Theorem^[The CLT "states the following. Let $X_1, X_2, X_3, ..., X_n$ denote a random sample of $n$ independent observations from a population with overall expected value (average) $\mu$ and a finite variance $\sigma^2$, and let $\bar{X_n}$ denote the sample mean of that sample (which is itself a random variable). Then the limit as $n \to \infty$ of the distribution of $\frac {\bar {X_n} - \mu}{\sigma_{\bar X_n}}$, where $\sigma_{\bar X_n} = \sigma/\sqrt{n}$ [@wikipedia]."] suggests the mean and variance of the normal distribution will converge to the mean and variation of the source (exponential) distribution as the number of sample means increase.

Before converting the CLT to code, several variables are set up as constants (see Code Segment 1) to ensure consistent values throughout the code's execution. These are constants because programming discipline 

\textbf{Code Block 1}
\scriptsize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}
LAMBDA       <- 0.2                     # given in the problem
SAMPLE_SIZE   <- 40                      # given in the problem
mu           <- 1/LAMBDA                # defined by exponential distribution
SIGMA        <- 1/LAMBDA                # defined by exponential distribution
variance     <- SIGMA^2                 # defined by probability theory
SAMPLE_ERR     <- SIGMA/sqrt(SAMPLE_SIZE)  # defined by probability theory 
```
\normalsize

The first step in converting the CLT to code is the generation of samples. Rather than generating a single sample at a time, the $\textbf{\textit{generateExponentialData(samples)}}$ function, creates a matrix with $\textit{SAMPLE\_SIZE = 40}$ and $\textit{sample}$, where sample is the number of samples required by the user. The matrix will contain the exact amount of data to meet the user's request. For example, if the user needs 1000 samples, the function will create a $40 \times 1000$ matrix.

\textbf{Code Block 2}
\scriptsize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}
generateExponentialData <- function(sample) {
  simData <- matrix(rexp(sample*SAMPLE_SIZE, LAMBDA), nrow = SAMPLE_SIZE, ncol = sample)
  return (simData)
}
```
\normalsize

### $\textbf{Mean and Variance Convergence}$

With the ability to create simulated data from an exponential distribution, the next step is to collect statistical data to show the convergence of the mean and variance of the sample means distribution. The $\textbf{\textit{calculateSampleMeansStats(sampleRepetition)}}$ function, where $\textit{sampleRepetition}$ is a list of sample values, is used to generate a ${sampleStats}$ data frame. The columns of the ${sampleStats}$ data frame contain the values of $\mu$ and $variance$. It also includes two additional values $muErr$ and $varErr$ that contain absolute error values for $\mu$ and $variance$ respectively. The rows of the ${sampleStats}$ data frame contain values of each column for each element of $\textit{sampleRepetition}$.

The $\textbf{\textit{calculateSampleMeansStats(sampleRepetition)}}$ function computes the ${simData}$ for each sampleRepetition. The process is 

1 Loop through the values of the $\textit{sampleRepetition} list.

+ Call $\textbf{\textit{generateExponentialData(samples)}}$ with the current $\textit{sampleRepetition}$ value and get the corresponding $\textit{sampleRepetition} ${simData}$ matrix.

+ Call $\textbf{\textit{colMeans(simData)}}$ to get a list of the means for each column in the ${simData}$ matrix to get the sample means

+ Call the mean and var functions to get the mean value and variation of the sample means

+ Store those results and others by binding them as a row to the $\textit{sampleStats}$ data frame.

+ Return to the for-loop

2 Set the column names

3 Add an $\textit{OffsetVar}$ for use in generating the convergence image.

For example, let, $\textit{sampleRepetition} = c(10,20, 30)$. The resulting ${sampleStats}$ data frame will contain three rows. The first will store the mean, variation and error values for the a sample means from a $sampleRepetition = 10$, the second would store the data for a $sampleRepetition = 20$, and the third for a  $sampleRepetition = 30$. 

\textbf{Code Block 3}
\scriptsize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}
calculateSampleMeansStats <- function (sampleRepetition)
{
  sampleStats <- data.frame(N_obs = integer(), mu = double(), muErr = double(),
                            variation = double(), varErr = double())

  for (sample in 1:length(sampleRepetition)) {
    simData       <- generateExponentialData(sampleRepetition[[sample]])
    sampleMeans   <- colMeans(simData)
    xbar          <- mean(sampleMeans)
    sig_2         <- var(sampleMeans)

    sampleStats  <- rbind(sampleStats, c(sampleRepetition[sample], xbar, abs((MU - xbar)/xbar),
                                         sig_2, abs((SAMPLE_VAR - sig_2)/sig_2)))
  }
  colnames(sampleStats) <- c("NRep", "Mean", "Absolute\nError of\nMean",
                             "Variance", "Absolute\nError of\nVariance")
  sampleStats <- cbind(sampleStats, OffsetVar = sampleStats$Variance + 5)
  
  return (sampleStats)
}
```
\normalsize

The sampleStats data frame from function ??? is converted to an image in convergenceImage. The most significant aspects of the function are:

1 ggplot is used to plot $\textit{sampleStats\$Mean}$, $\textit{sampleStats\$Variance}$, and the constants $\mu$, and  $\textit{variance}$.

2 The axis on the left of the plot is the "Mean" axis, the axis on the right of the plot is the Variance axis. 

3 The Variance axis uses the $\textit{sampleStats\$OffsetVar}$ value to shift the $\textit{sampleStats\$Variance}$ value to match the Variance axis.

4 The y-axis, Sample Size, is a log axis. The sample repetitions are $(10, 20, 30, 40, 100, 1000, 10000, 100000, 1000000)$
\newline

\textbf{Code Block 4}
\scriptsize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}
convergenceImage <- function(sampleRepetition)
{
  sampleStats <- calculateSampleMeansStats(sampleRepetition)
  graphTics   <- c(10, 100, 1000, 10000, 100000, 1000000)

  plt <- ggplot(sampleStats, aes(x = as.numeric(NRep))) +
    geom_hline(yintercept = 5, color="#ffd470", linewidth = 0.5) +
    geom_hline(yintercept = 5.625, color="#a5f7a1", linewidth = 0.5) +
    geom_line(aes(y=OffsetVar, color='Variance')) + 
    geom_line(aes(y=Mean, color='Mean')) +
    
    <Additional ggplot2 formatting>

  ggsave(plot = plt, width = 4.0, height = 2.5, dpi = 300, filename = "converge.png")
}

```
\normalsize

### $\textbf{Convergence Image}$

The image generated by convergenceImage (Figure 2), shows the convergence of the sample means distribution's mean value in orange and mean value of the exponential distribution $\mu = 5.0$ in light orange. Likewise, the sample means' variance is shown in green and the exponential distribution's variance $variance = 0.625$ is shown in light green.

\begin{wrapfigure}{r}{0.4\textwidth}
  \centering
    \includegraphics[width=\linewidth]{converge.png}
\end{wrapfigure}

This plot satisfies the first two requirements for Part I:

1 \textbf{The theoretical mean of the sample means converges to the same mean as the exponential distribution}. As the number of values in the sample means increases, the mean of the sample means approaches the theoretical value predicted by the CLT. The solid orange line osciallates about $\mu$ until $n \approx 1000$, then it rapidly converges to $\mu$.

2 \textbf{The theoretical variance of the sample means converges to the same variance as the exponential distribution}. As the number of values in the sample means increases, the variance of the sample means approaches the theoretical value predicted by the CLT. The solid green line oscillates about population $variance$ until $n \approx 8000$, then it rapidly converges to the population $variance$.

With the first two requirements satisfied, the next section will demonstrate will demonstrate the the third requirement, the sample means distribution approximates $N(\mu, \sigma^2)$.

### $\textbf{The sample means distribution approximates $N(\mu, \sigma^2)$}$

To demonstrate the sample means distribution approximates $N(\mu, \sigma^2)$, the code will generate a set of four plots showing the histogram and density curve fit to it, the curve $N(\mu, \sigma^2)$ predicted by the CLT, and two lines showing the means of the fitted and theoretical distributions. The plots are based on sample means with 10, 30, 40, and 1000 samples.

The code to create the sample means approximation (Code Sample 5) does the following:

1 Create one sample matrix for each value in the sample repetition list

2 Generate a list of sample means

+ Compute the mean of each column of the matrix for each matrix.

+ Store each sample mean set in a list.

3 Transform each sample means set to a standard normal distribution, using the Z-transformation: 

\begin{equation}
\frac {\bar {X_n} - \mu}{\sigma_{\bar X_n}}.
\end{equation}

this will ensure the variance is computed around $\mu = 5$, and not $\mu = 0$.

4 Transform each sample set back to the original mean, $\mu = 5$.

5 Plot the result.

\textbf{Code Block 5}
\scriptsize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}
normalDistributionImages <- function(sampleRepetition)
{
  transformToN <- function(sample) {
    (sample - MU)/SAMPLE_ERR + MU
  }

  for (i in 1:length(sampleRepetition)) {
    simData[[i]]   <- generateExponentialData(sampleRepetition[i])
    colData[[i]]   <- colMeans(simData[[i]])
    sampleMeans[[i]] <- data.frame(pdf = c(unlist(lapply(colData[[i]], transformToN))))

    pltList[[i]] <- ggplot(sampleMeans[[i]], aes(x = pdf)) +
      stat_function(fun = function (x) dnorm(x, mean =  5, sd = 1),
        color = "#00bfb2", fill = "#00bfb2", geom = "area", alpha = 0.8) +
      geom_density(alpha = 0.3, color = "#000000", fill="#000000")  +
      geom_histogram(aes(y = after_stat(density)), breaks = binRange,
                     alpha = 0.2, color = "#505050", linewidth = 0.2) +
      geom_vline(aes(xintercept=mean(pdf)), color="#000000", linewidth = 0.5, linetype = 2) +
      geom_vline(aes(xintercept = MU), color="#00bfb2", linewidth = 0.5, linetype = 2) +
  }

  plt <- ggarrange(pltList[[1]], pltList[[2]], pltList[[3]], pltList[[4]],
          labels = label, ncol = 2, nrow = 2)
  ggsave(plot = plt, width = 6.0, height = 4.0, dpi = 300, filename = "distribution.png")
}

```
\normalsize

The images created by normalDistributionImages are shown in Figure 3. 

\begin{wrapfigure}{r}{0.5\textwidth}
  \centering
    \includegraphics[width=\linewidth]{distribution.png}
\end{wrapfigure}

Each image includes five parts: the normal distribution $N(\mu, \sigma^2)$, the histogram of the corresponding sample means, a curve approximating the pdf of the histogram, a vertical line centered on the histogram pdf, and a vertical line centered on the normal curve.

1) The main observation from the images is the evolution of the approximate pdf (black outline with gray interior) from some nonlinear curve to a smoother normal-like curve. This is demonstrated by the $N(5, 25)$ curve overlaying the nonlinear curve. As $n$ increased from 10 to 1000, histogram pdf approaches the shape of the normal pdf. 

2) The separation of the histogram mean line and the normal mean line decreases as the $n$ increases. This shows the two lines 

This plot satisfies the last requirement for Part I:

1 \textbf{The sample means distribution approximates $N(\mu, \sigma^2)$ }. As $n$ increases, the shape of the curve approaches the shape of $N(\mu, \sigma^2)$. As the answers to requirements 1 and 2 show the convergence of both the mean and variance of the approximate pdf to the normal pdf, the CLT prediction is correct.




# Part II
## Basic Inferential Data Analysis



\begin{wrapfigure}{r}{0.5\textwidth}
  \centering
    \includegraphics[width=\linewidth]{tooth.png}
\end{wrapfigure}

\begin{wrapfigure}{r}{0.5\textwidth}
  \centering
    \includegraphics[width=\linewidth]{tooth-supp.png}
\end{wrapfigure}













# ################################################





\break



## Simulating an Exponential Distribution

- Sample Mean versus Theoretical Mean: Include figures with titles. In the figures, highlight the means you are comparing. Include text that explains the figures and what is shown on them, and provides appropriate numbers.
    
## Simulating an Exponential Distribution

- Sample Variance versus Theoretical Variance: Include figures (output from R) with titles. Highlight the variances you are comparing. Include text that explains your understanding of the differences of the variances.
    
## Simulating an Exponential Distribution

- Distribution: Via figures and text, explain how one can tell the distribution is approximately normal.




The objective of Part I is to demonstrate the validity of the Central Limit Theorem (CLT). 


The CLT"states the following. Let $X_1, X_2, X_3, ..., X_n$ denote a random sample of $n$ independent observations from a population with overall expected value (average) $\mu$ and a finite variance $\sigma^2$, and let $\bar{X_n}$ denote the sample mean of that sample (which is itself a random variable). Then the limit as $n \to \infty$ of the distribution of $\frac {\bar {X_n} - \mu}{\sigma_{\bar X_n}}$, where $\sigma_{\bar X_n} = \sigma/\sqrt{n}$ [@wikipedia]." In other words, the distribution of sample means will approach $N(0,1)$ as the number of samples increases, regardless of the distribution of the random values.

To demonstrate the validity the CLT, the document code generate two images. The first image is a set of four plots showing the sample mean distribution with sample sizes of 10, 30, 40, and 1000. The second image shows the mean and variance values for sample mean distributions with sample repetitions of 10, 20, 30, 40, 100, 1000, 10000, 100000, and 1000000.

### Generate Sample Means

The first step in the generation of both images is the generation of samples means lists. The $\textbf{\textit{generateSampleMeansLists}}$ function is responsible for the generation of the random values from the exponential mean and converting those values to the sample means list. Given the sample repetitions set $\{10, 30, 40, 1000\}$, the simulation will generate four matrices of sizes $40 \times 10$, $40 \times 30$, $40 \times 40$, and $40 \times 1000$. For each matrix, the function computes the mean of each column and stores the means in a list.

The $\textit{sampleMeansLists}$ contain the cleaned raw data.

### Create Sample Means Distribution Plots

The CLT implies that the sample means distribution is expected to converge to a normal distribution $N(1/\lambda, 1/\lambda^2)$ as the number of repetitions increases. To verify the theorem, the doucment code should compute the absolute difference between each point on the two curves. To do this would require a signifant amount of programming and some math outside of the scope of the course. Therefore, this the exercise, will generate images for repeat values of n = 10, 30, 40, and 1000 and it will report the values of the mean and variance of the sample mean for repeat values of 10, 20, 30, 40, 100, 1000, 10000, 100000, and 1000000. The images will show the convergence of the sample means distribution to the normal mean $N(1/\lambda, 1/\lambda^2)$. The data report will show the convergence of the mean and variance of the sample mean to $1/\lambda$, and $1/\lambda^2$ respectively. 

Both the image and the report rely on the $\textbf{\textit{generateSampleMeansLists}}$ function to create a list of sample means $\textit{sampleMeansLists}$, where each member of the list is a sample means. Each of the sample means is the size of the repetition value used to generate the sample means. In other words, the sample means for a repetition value of ten will have tem elements, the one with a repetition value of forty will have forty elements, etc. (see Appendix I for the specific code).

To create the Sample Means Distribution images, the code processes the $\textit{sampleMeansLists}$ data as follows

- Convert the $\textit{sampleMeansLists}$ data to the standard normal curve using

\begin{equation}
\frac {\bar {X_n} - \mu}{\sigma_{\bar X_n}}
\end{equation}

- Translate the standard normal curve back to its origional location by adding 5.0 to each element of the distribution.

+ After this process, the sample means distribution should be normalized and should have the same mean and variance as the Standard Normal Distribution.

+ By increasing the number of repetitions, the sample means distribution should look like $N(5,1)$.

Figures 1 a-d show the histogram of the sample means, an approximation of the sample means distribution, the normal distribuion $N(5,1)$, a vertical line at the mean of the sample distribution and a second vertical line at the mean of $N(5,1)$. The images correspond to repetition $n = 10$, $n = 30$, $n = 40$, and $n = 1000$, and each images shows how the sample means distribution gets closer to the $N(5, 1)$ as $n$ increases. The two vertical lines move closer together until they overlap at $\mu = 5.0$, further supporting the assertion regarding the CLT.

```{r echo=FALSE, out.width = "75%", fig.align = "center"}
knitr::include_graphics("distribution.png")
```

### Quantitative Comparison of Sample Means and Standard Normal Distributions

The qualitative 

In addition to the qualitative comparison of the two distributions, the document code also produces a table to reporti the convergence of the sample means distribution with the normal distribution. Table 1 shows  




#### ==============



Part 1 is an analysis of the CLT using a simulation of a non-Gaussian distribution. Each simulation will consist of $n$ samples, and each sample will consist of forty observation taken from an exponential distribution . The project will run the simulation several times each using a different value of $n$. 

For each sample, the program will record the mean and standard values to construct a distribution of the sample means. If the CLT is correct, then the expected result should be a Gaussian distribution with a mean and standard deviation of the rate constant used in the exponential distribution.




## #########################


# Bibliography
<!-- https://stackoverflow.com/questions/68372960/how-to-wrap-text-around-charts-in-a-rmarkdown-knit-to-pdf-document -->

[wikipedia https://en.wikipedia.org/wiki/Exponential_distribution]
[mean https://statproofbook.github.io/P/exp-mean.html]
[variance https://statproofbook.github.io/P/exp-var.html]
[reference lecture notes showing mu = 3.5 for rolling dice]
[scribbr https://www.scribbr.com/statistics/central-limit-theorem/]
[JHU-Course https://www.coursera.org/learn/statistical-inference/home/week/1]
[JHU-Project https://www.coursera.org/learn/statistical-inference/peer/3k8j5/statistical-inference-course-project]

[Crampton, E. W. (1947). The growth of the odontoblast of the incisor teeth as a criterion of vitamin C intake of the guinea pig. The Journal of Nutrition, 33(5), 491--504. 10.1093/jn/33.5.491]

# Appendix 1: Code

