---
title: "Test"
author: "Kevin Glass"
date: "`r Sys.Date()`"
output: pdf_document
---

---
title           : "Distributions and Their Uses"
author          : "Kevin Glass"
date            : "`r Sys.Date()`"
output          : pdf_document

header-includes :
  - \usepackage{wrapfig}
  - \usepackage{caption}
  - \usepackage{xcolor}
  - \usepackage{xelatex}
  - \captionsetup[figure]{font = footnotesize}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{css, echo=FALSE}
.watch-out {
  background-color: gray;
  border: 3px solid red;
  font-weight: bold;
}
```

## Simulation setup

### Constants

```{r constants, echo=FALSE, message=FALSE, results = 'hide'}
options(scipen = 999)
options(digits = 3)

# Verify the simulation data is formatted as a list of n matrices
VERIFY_SOURCE_FILE = FALSE    # store to file
VERIFY_SOURCE_SCR  = FALSE    # print to screen
RUN_SIM_VERIFY     = FALSE    # run verification tests

# Verify the mean column data is stored as a list of lists.
VERIFY_MEAN_DISTRIB_FILE  = FALSE
VERIFY_MEAN_DISTRIB_SCR   = FALSE
RUN_VERIFY_MEAN_DISTRIB   = FALSE

# Verify the mean distribution images
VERIFY_MEAN_DIST_IMG      = FALSE
VERIFY_MEAN_DIST_IMG_FILE = FALSE
RUN_MEAN_DIST_IMG         = FALSE

# Verify the simulation data
VERIFY_SAMPLE_STATS_FILE  = FALSE
VERIFY_SAMPLE_STATS_SCR   = FALSE
RUN_VERIFY_STATS          = FALSE

# Verify the mean convergence image
VERIFY_CONVERGE_IMG       = FALSE
RUN_VERIFY_CONVERGE_IMG   = FALSE

# Verify the Tooth image
VERIFY_TOOTH_DATA         = FALSE
RUN_VERIFY_TOOTH_DATA     = FALSE

# Verify the TOOTH image
VERIFY_TOOTH_IMG          = FALSE
RUN_VERIFY_TOOTH_IMG      = FALSE

# Verify the convergence table
VERIFY_CONVERGE_TABLE     = FALSE
RUN_VERIFY_CONVERGE_TABLE = FALSE

# Verify the convergence table
VERIFY_TOOTH_SUMMARY      = FALSE
RUN_VERIFY_TOOTH_SUMMARY  = FALSE

# Verify the convergence table
RUN_CALCULATE_AREA_D      = FALSE
VERIFY_CALCULATE_AREA_D   = FALSE

# Verify the convergence table
EXECUTE                   = TRUE

library(dplyr)
library(ggplot2)
library(gridExtra)
library(knitr)
library(kableExtra)
library(ggpubr)
library(matrixStats)
library(data.table)
library(sfsmisc)

set.seed(2063)

LAMBDA       <- 0.2
SAMPLE_SIZE   <- 40
MU           <- 1/LAMBDA
SIGMA        <- 1/LAMBDA
VARIANCE     <- SIGMA^2
SAMPLE_ERR     <- SIGMA/sqrt(SAMPLE_SIZE)
SAMPLE_VAR   <- SAMPLE_ERR^2

if(FALSE)
{
  print("CONSTANTS")
  print(paste0("LAMBDA            = ", LAMBDA))
  print(paste0("SAMPLE_SIZE        = ", SAMPLE_SIZE))
  print(paste0("MU                = ", MU))
  print(paste0("SIGMA             = ", SIGMA))
  print(paste0("VARIANCE          = ", VARIANCE))
  print(paste0("SAMPLE_ERR          = ", SAMPLE_ERR))
}

```
<!-- ###################################################################################### -->
<!-- ###################################################################################### -->
<!-- ###################################################################################### -->

```{r generateSimulationData, echo=FALSE}

# generateSimulationData <- function(sampleRepetition)
# {
#   if(RUN_SIM_VERIFY & VERIFY_MEAN_DISTRIB_SCR | FALSE)
#   {
#     print("generateSampleMeansLists: verify inputs")
#     print(paste0("sampleRepetitions = ", sampleRepetition))
#     print(paste0("SAMPLE_SIZE   = ", SAMPLE_SIZE))
#     print(paste0("LAMBDA       = ", LAMBDA))
#   }
# 
#   # ----------------------------------------------------------------------------------
#   simData <- list()
# 
#   for (i in 1:length(sampleRepetition)) {
#     simData[[i]] <- matrix(rexp(sampleRepetition[i]*SAMPLE_SIZE, LAMBDA),
#                                    nrow = SAMPLE_SIZE, ncol = sampleRepetition[i])
#   }
# 
# 
#   # ----------------------------------------------------------------------------------
# 
#   if(RUN_SIM_VERIFY & VERIFY_SOURCE_FILE | FALSE)
#   {
#     print("generateSampleMeansLists: store in simData_#.csv")
#     filename <- paste0("simData_", sampleRepetition[i], ".csv")
#     write.csv(sampleMatrix, filename, row.names=FALSE)
#   }
# 
#   if(RUN_SIM_VERIFY & VERIFY_SOURCE_SCR | FALSE)
#   {
#     print("generateSampleMeansLists: ")
#     print(simData)
#   }
# 
#   return (simData)
# }
# 
# if(RUN_SIM_VERIFY)
# {
#   sampleRepetition  <- c(10, 20, 30, 40)
# 
#   simData <- generateSampleMeansLists(sampleRepetition)
# 
#   print("RUN_SIM_VERIFY: simData")
#   print(simData)
# }

```

<!-- # Part I -->

<!-- ### Generate Mean Distributions -->

```{r generateMeanDist, echo=FALSE}

# generateMeanDist <- function(sampleRepetition, simData)
# {
#   if(VERIFY_MEAN_DISTRIB_SCR | FALSE)
#   {
#     print("generateMeanDist: verify inputs")
#     print(paste0("sampleRepetitions = ", sampleRepetition))
#     print(paste0("LAMBDA            = ", LAMBDA))
#     print(paste0("MU                = ", MU))
#     print(paste0("VARIANCE            = ", VARIANCE))
#     print(paste0("SAMPLE_ERR         = ", SAMPLE_ERR))
#     # print("simData = ")
#     # print(simData)
#     print("Test sim data separately")
#   }
# 
#   # ----------------------------------------------------------------------------------
#   # distributions     <- list()
#   sampleMeansLists <- list()
# 
#   for (i in 1:length(sampleRepetition)) {
#     sampleMeansLists[[i]]   <- colMeans(simData[[i]])
#   }
# #
# #   transformToN <- function(sample) {
# #     (sample - MU)/SAMPLE_ERR
# #   }
# #
# #   for (i in 1:length(sampleRepetition)) {
# #     sampleMeansLists[[i]]   <- lapply(distributions[[i]], transformToN)
# #     sampleMeansLists[[i]]   <- c(unlist(sampleMeansLists[[i]]))
# #   }
# 
#   if(VERIFY_MEAN_DISTRIB_SCR | FALSE)
#   {
#     for (i in 1:length(sampleRepetition)) {
#       # print("distributions = ")
#       # print(distributions[i])
#       print("sampleMeansLists = ")
#       print(sampleMeansLists[i])
#     }
#   }
# 
#   # ----------------------------------------------------------------------------------
# 
#   if(VERIFY_MEAN_DISTRIB_FILE | FALSE)
#   {
#     print("generateMeanDist: store in simData_#.csv")
#     for (i in 1:length(sampleRepetition)) {
#       filename <- paste0("sampleMeansLists_", sampleRepetition[i], ".csv")
#       write.csv(sampleMeansLists[[i]], filename, row.names=FALSE)
# 
#       filename2 <- paste0("distributions_", sampleRepetition[i], ".csv")
#       write.csv(distributions[[i]], filename2, row.names=FALSE)
#     }
#   }
# 
#   if(VERIFY_MEAN_DISTRIB_SCR | FALSE)
#   {
#     print("generateMeanDist: sampleMeansLists")
#     print(sampleMeansLists)
#   }
# 
#   return (sampleMeansLists)
# }
# 
# if(RUN_VERIFY_MEAN_DISTRIB)
# {
#   sampleRepetition  <- c(10, 20, 30, 40)
# 
#   simData           <- generateSampleMeansLists(sampleRepetition)
#   sampleMeansLists <- generateMeanDist(sampleRepetition, simData)
#   # sampleMeansLists <- generateSampleMeansLists(sampleRepetition)
# 
#   print("RUN_VERIFY_MEAN_DISTRIB: sampleMeansLists")
#   print(sampleMeansLists)
# }

```

<!-- ###################################################################################### -->
<!-- ###################################################################################### --> 
<!-- ###################################################################################### -->

### Generate Exponential Data

```{r generateExponentialData,  echo=FALSE}
generateExponentialData <- function(sample)
{
  simData <- matrix(rexp(sample*SAMPLE_SIZE, LAMBDA), nrow = SAMPLE_SIZE, ncol = sample)
  
  if(VERIFY_SAMPLE_STATS_SCR | FALSE)
  {
    print("generateExponentialData: verify inputs")
    print(paste0("MU           = ", MU))
    print(paste0("var          = ", VARIANCE))
    print(paste0("sample      = ", sample))
    print(paste0("SAMPLE_SIZE   = ", SAMPLE_SIZE))
    print("simData = ")
    print(simData)
    # print("Test simData separately")
  }
  return (simData)
}
```

### Calculate Sample Mean Stats

```{r calculateSampleMeansStats, echo=FALSE}
calculateSampleMeansStats <- function (sampleRepetition)
{
  sampleStats <- data.frame(N_obs = integer(), mu = double(), muErr = double(),
                            variation = double(), varErr = double())

  for (sample in 1:length(sampleRepetition)) {
    simData       <- generateExponentialData(sampleRepetition[[sample]])
    sampleMeans   <- colMeans(simData)
    if(VERIFY_SAMPLE_STATS_SCR | FALSE)
    {
      print("generateSampleMeansLists: verify inputs")
      print(paste0("MU           = ", MU))
      print(paste0("var          = ", VARIANCE))
      print("sampleMeans = ")
      print(sampleMeans)
      # print("Test sampleMeans separately")
      # print("simData = ")
      # print(simData)
      print("Test simData separately")
    }
 
    xbar          <- mean(sampleMeans)
    sig_2         <- var(sampleMeans)

    sampleStats  <- rbind(sampleStats,
                           c(sampleRepetition[sample], xbar, abs((MU - xbar)/xbar),
                             sig_2, abs((SAMPLE_VAR - sig_2)/sig_2)))
  }
  colnames(sampleStats) <- c("NRep", "Mean", "Absolute\nError of\nMean",
                             "Variance", "Absolute\nError of\nVariance")
  # -----------------------------------------------------------------------------

  sampleStats <- cbind(sampleStats, OffsetVar = sampleStats$Variance + 5)

  return (sampleStats)
}

```


# Part II

### Teeth data

```{r generateToothData, echo=FALSE}

generateToothData <- function (ToothGrowth)
{
  if(RUN_VERIFY_TOOTH_DATA | FALSE)
  {
    print("generateToothData: verify inputs")
    print("ToothGrowth = ")
    print(ToothGrowth)
  }

  # -----------------------------------------------------------------------------
  allFactor   <- as.factor(paste0(ToothGrowth$supp, "-", ToothGrowth$dose))
  ToothGrowth <- cbind(ToothGrowth, allFactor)
  # -----------------------------------------------------------------------------

  if(VERIFY_TOOTH_DATA & RUN_VERIFY_TOOTH_DATA | FALSE)
  {
    print("generateToothData: output")
    print("ToothGrowth = ")
    print(ToothGrowth)
  }

  return (ToothGrowth)

}

if(RUN_VERIFY_TOOTH_DATA | FALSE)
{
  doses      = c(0.5, 1.0, 2.0) # mg/day
  supplement = c("OJ", "AA")    # supplement of AA, OJ - Orange Juice, AA - Ascorbic Acid

  nPigs    <- 60
  nLength  <- nPigs/(length(doses)*length(supplement))
  nBins    <- nPigs/nLength
  # bw       <- c(3, 3, 4, 3, 3, 4)

  ToothGrowth <- generateToothData(ToothGrowth)
  print("RUN_VERIFY_TOOTH_DATA: ToothGrowth data")
  print(ToothGrowth)
}


```

### Generate Tooth Image

<!-- , results = 'hide' -->

```{r echo = FALSE, warning = FALSE, fig.dim = c(8, 4)}

generateToothImage <- function (ToothGrowth)
{
  if(VERIFY_TOOTH_IMG | FALSE)
  {
    print("generateToothImage: verify inputs")
    print("ToothGrowth = ")
    print(ToothGrowth)
  }

  ToothGrowth$dotColor <- c(rep("blue",10),
                            rep("green",10),
                            rep("orange",10),
                            rep("purple",10),
                            rep("yellow",10),
                            rep("red",10))
  
  plt <- ggplot(ToothGrowth, aes(x = allFactor, y = len)) +
    geom_boxplot() +
    geom_dotplot(binaxis='y',
                 stackdir='center',
                 dotsize = 0.5,
                 fill = ToothGrowth$dotColor) +
    labs(title="Effect of Vitamin C on Tooth Growth",
         subtitle="Supplement and Dosage",
         caption="Source: C. I. Bliss (1952). The Statistics of Bioassay. Academic Press.",
         x="Supplement (OJ, VC), Dosage(0.5, 1.0, 2.0)",
         y="Tooth Length")
  
  
  ggsave(plot = plt, width = 4.0, height = 3.5, dpi = 300,
         filename = "teeth.png")
}

if(RUN_VERIFY_TOOTH_IMG)
{
  ToothGrowth <- generateToothData(ToothGrowth)
  generateToothImage(ToothGrowth)
  print("RUN_VERIFY_TOOTH_IMG: check image")
}

```



```{r teethData, echo=FALSE}

# Now in the second portion of the project, we're going to analyze the ToothGrowth data in the R datasets package.
# Load the ToothGrowth data and perform some basic exploratory data analyses

# Provide a basic summary of the data.

# Use confidence intervals and/or hypothesis tests to compare tooth growth by supp and dose. (Only use the techniques from class, even if there's other approaches worth considering)

# State your conclusions and the assumptions needed for your conclusions.

# The response is the length of odontoblasts (cells responsible for tooth
# growth) in 60 guinea pigs. Each animal received one of three dose levels of
# vitamin C (0.5, 1, and 2 mg/day) by one of two delivery methods, orange juice
# or ascorbic acid (a form of vitamin C and coded as AA).
# https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/ToothGrowth

```

## Images

### Base Image

```{r baseImage, echo = FALSE, warning = FALSE}
baseImage <- function(n)
{
  plot <- ggplot() +
    stat_function(fun = dnorm, args = c(mean =  5, sd = 1), n = n,
        color = "#000000", fill = "#000000", geom = "area", alpha = 0.2) +
    stat_function(fun = dexp, args = c(rate =  0.2), n = n,
        color = "#00bfb2", fill = "#00bfb2", geom = "area", alpha = 0.5) +
    ggtitle("Exponential and Normal Distributions") +
    scale_x_continuous(limits = c(0, 10), "Mean") +
    scale_y_continuous(limits = c(-0.1, 0.5), "Density")

  ggsave(plot = plot, width = 6.0, height = 4.0, dpi = 300, filename = "base.png")
}
```

### Convergence Image

```{r convergenceImage, echo = FALSE, results = 'hide'}
convergenceImage <- function(sampleRepetition)
{
  sampleStats <- calculateSampleMeansStats(sampleRepetition)

  if(VERIFY_CONVERGE_IMG | FALSE)
  {
    print("calculateSampleMeansStats: verify inputs")
    print(paste0("MU           = ", MU))
    print(paste0("var          = ", VARIANCE))
    # print("sampleRepetition = ")
    # print(sampleRepetition)
    print("Test sampleRepetition separately")
    print("sampleStats = ")
    print(sampleStats)
    # print("Test sampleStats separately")
  }
  graphTics   <- c(10, 100, 1000, 10000, 100000, 1000000)

  plt <- ggplot(sampleStats, aes(x = as.numeric(NRep))) +
    geom_hline(yintercept = 5, color="#e8a200", linewidth = 0.5, linetype = 2) +
    geom_hline(yintercept = 5.625, color="#099e02", linewidth = 0.5, linetype = 2) +
    geom_line(aes(y=OffsetVar, color='Variance')) +
    geom_line(aes(y=Mean, color='Mean')) +
    scale_x_log10(breaks = graphTics, limits = c(4.9, 1000000.0)) +
    # scale_x_log10(breaks = graphTics, limits = c(0.1, 1000000.0)) +
    scale_y_continuous(limits = c(4.7, 6.0), "Mean",
    sec.axis = sec_axis(~ . -5, name = "Variance")) +
    ggtitle("Sample Mean and Variance") + xlab("Sample Size (log n)") +
    scale_color_manual(
      name='Statistic', breaks=c('Variance', 'Mean'),
      values=c('Mean'='#e8a200', 'Variance'='#099e02')) +
    theme(plot.title = element_text(size = 10, hjust = 0.5),
          axis.title.x = element_text(size = 8),
          axis.title.y = element_text(size = 8),
          axis.text.x = element_text(face="bold", size=6),
          axis.text.y = element_text(face="bold", size=6),
          legend.title = element_text(size = 6),
          legend.text = element_text(size = 6),
          legend.key.size = unit(2, 'mm'),
          legend.position = c(0.85, 0.55))

  ggsave(plot = plt, width = 4.0, height = 2.5, dpi = 300,
         filename = "converge.png")
}

```

### Normal Distribution Images

```{r imageDistribution, echo = FALSE, warning = FALSE, fig.dim = c(6, 5)}
normalDistributionImages <- function(sampleRepetition)
{
  binRange          <- seq(2.0, 9.0, by = 0.25)

  if(VERIFY_MEAN_DIST_IMG | FALSE)
  {
    print("imageNormalDistribution: verify inputs")
    print(paste0("sampleRepetitions = ", sampleRepetition))
    print(paste0("SAMPLE_SIZE        = ", SAMPLE_SIZE))
    print(paste0("LAMBDA            = ", LAMBDA))
    print(paste0("MU                = ", MU))
    print(paste0("VARIANCE          = ", VARIANCE))
    print(paste0("SAMPLE_ERR          = ", SAMPLE_ERR))
    print("binRange = ")
    print(binRange)
    # print("Test binRange separately")
    print("sampleMeansLists = ")
    print(sampleMeansLists)
    # print("Test sampleMeansLists separately")
  }
  # -----------------------------------------------------------------------------
  label <- c("a", "b","c","d")
  pltList <- list()

  transformToN <- function(sample) {
    (sample - MU)/SAMPLE_ERR + MU
  }

  simData  <- list()
  colData  <- list()
  sampleMeans  <- list()
  sourceData  <- list()
  # for (i in 1:length(sampleRepetition)) {
  #   simData[[i]]   <- generateExponentialData(sampleRepetition[i])
  #   colData[[i]]   <- colMeans(simData[[i]])
  # }
  # 
  # for (i in 1:length(sampleRepetition)) {
  #   sampleMeans[[i]] <- data.frame(pdf = c(unlist(lapply(colData[[i]], transformToN))))
  #   sourceData[[i]]  <- data.frame(pdf = c(unlist(lapply(simData[[i]], transformToN))))
  # }
  for (i in 1:length(sampleRepetition)) {
    # simData[[i]]   <- generateExponentialData(sampleRepetition[i])
    # colData[[i]]   <- colMeans(simData[[i]])
    # sampleMeans[[i]] <- data.frame(pdf = c(unlist(lapply(colData[[i]], transformToN))))
    # sourceData[[i]]  <- data.frame(pdf = c(unlist(lapply(simData[[i]], transformToN))))
    simData[[i]]   <- generateExponentialData(sampleRepetition[i])
    colData[[i]]   <- colMeans(simData[[i]])
    sampleMeans[[i]] <- data.frame(pdf = c(unlist(lapply(colData[[i]], transformToN))))
    sourceData[[i]]  <- data.frame(pdf = c(unlist(lapply(simData[[i]], transformToN))))
  # }
  # 
  # for (i in 1:length(sampleRepetition)) {

    if(VERIFY_MEAN_DIST_IMG | FALSE)
    {
      print("imageNormalDistribution: sampleMeans")
      print(sampleMeans[[i]])
      print(sourceData[[i]])
    }

    if(VERIFY_MEAN_DIST_IMG_FILE | FALSE)
    {
      print("generateMeanDist: store in simData_#.csv")
      filename <- paste0("sampleMeansListsIMG_", sampleRepetition[i], ".csv")
      write.csv(sampleMeansLists[[i]], filename, row.names=FALSE)

      filename2 <- paste0("sampleMeans", sampleRepetition[i], ".csv")
      write.csv(sampleMeans, filename2, row.names=FALSE)
    }

    pltList[[i]] <- ggplot(sampleMeans[[i]], aes(x = pdf)) +
      stat_function(fun = function (x) dnorm(x, mean =  5, sd = 1),
        color = "#00bfb2", fill = "#00bfb2", geom = "area", alpha = 0.8) +
      geom_density(alpha = 0.3, color = "#000000", fill="#000000")  +
      geom_histogram(aes(y = after_stat(density)), breaks = binRange,
                     alpha = 0.2, color = "#505050", linewidth = 0.2) +
      # geom_density(data = sourceData[[i]], alpha = 0.3, color = "#000000", fill="#000000")  +
      # lines(density(sourceData$pdf), col="blue", lwd=2) +
      geom_vline(aes(xintercept=mean(pdf)), color="#000000", linewidth = 0.5, linetype = 2) +
      geom_vline(aes(xintercept = MU), color="#00bfb2", linewidth = 0.5, linetype = 2) +
      geom_hline(yintercept=0, color="#000000", linewidth = 0.5) +
      ggtitle(paste0("Sample Mean with n = ", sampleRepetition[i])) +
      scale_x_continuous(limits = c(0, 10), "Mean") +
      scale_y_continuous(limits = c(-0.1, 0.8), "Density")
  }

  plt <- ggarrange(pltList[[1]], pltList[[2]], pltList[[3]], pltList[[4]],
          labels = label, ncol = 2, nrow = 2)
  ggsave(plot = plt, width = 6.0, height = 4.0, dpi = 300, filename = "distribution.png")
}

if(RUN_MEAN_DIST_IMG)
{
  sampleRepetition  <- c(10, 20, 30, 1000)
  binRange          <- seq(-3.0, 10.0, by = 0.5)

  simData           <- generateSampleMeansLists(sampleRepetition)
  sampleMeansLists <- generateMeanDist(sampleRepetition, simData)
  imageNormalDistribution(sampleRepetition, sampleMeansLists, binRange)

  print("RUN_MEAN_DIST_IMG: check image")
}

```


### Create Convergence Image


## Tables


### generateConvergeTable

```{r generateConvergeTable, echo = FALSE}
generateConvergeTable <- function (sampleRepetition)
{
  sampleStats <- calculateSampleMeansStats(sampleRepetition)

  if(VERIFY_CONVERGE_TABLE | FALSE)
  {
    print("imageConvergence: verify inputs")
    print(paste0("sampleStats  = ", sampleStats))
  }

  # -----------------------------------------------------------------------------

  resTable <- knitr::kable(sampleStats, "latex",
    caption = paste0("table"), digits = 3, align = "llll", row.names = TRUE) %>%
    kable_styling(bootstrap_options = c("striped", "hover"),
                  full_width = F,
                  # position = "left",
                  font_size = 8) %>%
    column_spec(column=1, width="0.2cm") %>%
    column_spec(column=2, width="1.0cm") %>%
    column_spec(column=3, width="0.7cm") %>%
    column_spec(column=4, width="1.5cm") %>%
    column_spec(column=5, width="1.0cm") %>%
    column_spec(column=6, width="1.5cm") %>%
    kable_classic_2()
  # -----------------------------------------------------------------------------

  return (resTable)

}

if(RUN_VERIFY_CONVERGE_TABLE)
{
  LAMBDA       <- 0.2
  SAMPLE_SIZE   <- 40
  MU           <- 1/LAMBDA
  var          <- MU^2/sqrt(SAMPLE_SIZE)
  sampleRepetition  <- c(10, 100, 1000, 10000, 100000, 1000000)

  simData           <- generateSampleMeansLists(sampleRepetition, SAMPLE_SIZE, LAMBDA)
  sampleMeansLists  <- calcSampleMeansLists(sampleRepetition, simData)
  sampleMeansStats  <- getSampleMeansStats(sampleRepetition, sampleMeansLists, MU, var)
  resTable          <- generateConvergeTable(sampleMeansStats)

  print("RUN_VERIFY_CONVERGE_TABLE: : resTable")
}

```


# Execute

```{r execute, echo = FALSE}

if(EXECUTE & TRUE)
{
  baseImage(100)

  sampleRepetition  <- c(10, 20, 30, 40, 100, 1000, 10000, 100000, 1000000)
  convergenceImage(sampleRepetition)

  resTable <- generateConvergeTable(sampleRepetition)

  sampleRepetition  <- c(10, 20, 40, 1000)
  normalDistributionImages(sampleRepetition)

  # print(paste0("mu = ", MU, " sample size = ", SAMPLE_SIZE, " var = ", var))
  # # histogram plots
  # sampleRepetition  <- c(10, 30, 40, 1000)
  # 
  # simData          <- generateExponentialData(sampleRepetition)
  # sampleMeansLists <- generateSampleMeansLists(sampleRepetition, simData)
  # 
  # imageNormalDistribution(sampleRepetition, sampleMeansLists, simData, binRange)

  # # convergence plot
  # sampleRepetition <- c(10, 20, 30, 40, 100, 1000, 10000, 100000, 1000000)
  # 
  # sampleMeansLists <- generateSampleMeansLists(sampleRepetition)
  # sampleMeansStats <- calculateSampleMeansStats(sampleRepetition, sampleMeansLists, MU, var)
  # # sampleStats      <- calculateSampleMeansStats(sampleRepetition, sampleMeansLists)
  # imageConvergencePlot(sampleRepetition, sampleMeansStats)
  # 
  # resTable <- generateConvergeTable(sampleMeansStats)
  
  # sampleMeansLists <- calcSampleMeansLists(sampleRepetition, simData)
  # sampleMeansStats  <- getSampleMeansStats(sampleRepetition, sampleMeansLists, MU, var)
  # resTable          <- generateConvergeTable(sampleMeansStats)

  # tooth plot
  # ToothGrowth <- generateToothData(ToothGrowth)
  # generateToothImage(ToothGrowth)
}

```

# --------------------------------
\newpage
# Overview

Part I of this project will produce a set of simulations designed to show the validity of the Central Limit Theorem (CLT). Part II will characterize the R "ToothGrowth" data set [@ToothGrowth] using statistical techniques presented on the Johns Hopkins Statistical Inference Online Course [@JHU].

# Part 1
## Simulating an Exponential Distribution

The simulation uses two probability distribution functions, the exponential and normal distributions. For reference, Figure 1 shows these both of the distributions.  

\begin{wrapfigure}{r}{0.3\textwidth}
  \centering
    \includegraphics[width=\linewidth]{base.png}
\end{wrapfigure}

The goal of the simulation is to establish three points:

1 \textbf{The theoretical mean of the sample means converges to the same mean as the exponential distribution}.

2 \textbf{The theoretical variance of the sample means converges to the same variance as the exponential distribution}.

3 \textbf{The sample means distribution approximates $N(\mu, \sigma^2)$ }.

To address these points, the simulation will produce IIIIII images, and IIIIII tables. These include plots showing the convergence of the sample means to the theoretical mean and variance, and a plot showing the convergence of the sample mean distribution to $N(\mu, \sigma^2)$.

WHAT ARE MU AND SIGMA? [wikipedia https://en.wikipedia.org/wiki/Exponential_distribution]

### \textbf{Setting up Simulation Data}

The Central Limit Theorem^[The CLT "states the following. Let $X_1, X_2, X_3, ..., X_n$ denote a random sample of $n$ independent observations from a population with overall expected value (average) $\mu$ and a finite variance $\sigma^2$, and let $\bar{X_n}$ denote the sample mean of that sample (which is itself a random variable). Then the limit as $n \to \infty$ of the distribution of $\frac {\bar {X_n} - \mu}{\sigma_{\bar X_n}}$, where $\sigma_{\bar X_n} = \sigma/\sqrt{n}$ [@wikipedia]."] suggests the mean and variance of the normal distribution will converge to the mean and variation of the source (exponential) distribution as the number of sample means increase.

Before converting the CLT to code, several variables are set up as constants (see Code Segment 1) to ensure consistent values throughout the code's execution. These are constants because programming discipline 

\textbf{Code Block 1}
\scriptsize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}
LAMBDA       <- 0.2                     # given in the problem
SAMPLE_SIZE   <- 40                      # given in the problem
mu           <- 1/LAMBDA                # defined by exponential distribution
SIGMA        <- 1/LAMBDA                # defined by exponential distribution
variance     <- SIGMA^2                 # defined by probability theory
SAMPLE_ERR     <- SIGMA/sqrt(SAMPLE_SIZE)  # defined by probability theory 
```
\normalsize

The first step in converting the CLT to code is the generation of samples. Rather than generating a single sample at a time, the $\textbf{\textit{generateExponentialData(samples)}}$ function, creates a matrix with $\textit{SAMPLE\_SIZE = 40}$ and $\textit{sample}$, where sample is the number of samples required by the user. The matrix will contain the exact amount of data to meet the user's request. For example, if the user needs 1000 samples, the function will create a $40 \times 1000$ matrix.

\textbf{Code Block 2}
\scriptsize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}
generateExponentialData <- function(sample) {
  simData <- matrix(rexp(sample*SAMPLE_SIZE, LAMBDA), nrow = SAMPLE_SIZE, ncol = sample)
  return (simData)
}
```
\normalsize

### \textbf{Mean and Variance Convergence}

With the ability to create simulated data from an exponential distribution, the next step is to collect statistical data to show the convergence of the mean and variance of the sample means distribution. The $\textbf{\textit{calculateSampleMeansStats(sampleRepetition)}}$ function, where $\textit{sampleRepetition}$ is a list of sample values, is used to generate a ${sampleStats}$ data frame. The columns of the ${sampleStats}$ data frame contain the values of $\mu$ and $variance$. It also includes two additional values $muErr$ and $varErr$ that contain absolute error values for $\mu$ and $variance$ respectively. The rows of the ${sampleStats}$ data frame contain values of each column for each element of $\textit{sampleRepetition}$.

The $\textbf{\textit{calculateSampleMeansStats(sampleRepetition)}}$ function computes the ${simData}$ for each sampleRepetition. The process is 

1 Loop through the values of the $\textit{sampleRepetition} list.

+ Call $\textbf{\textit{generateExponentialData(samples)}}$ with the current $\textit{sampleRepetition}$ value and get the corresponding $\textit{sampleRepetition} ${simData}$ matrix.

+ Call $\textbf{\textit{colMeans(simData)}}$ to get a list of the means for each column in the ${simData}$ matrix to get the sample means

+ Call the mean and var functions to get the mean value and variation of the sample means

+ Store those results and others by binding them as a row to the $\textit{sampleStats}$ data frame.

+ Return to the for-loop

2 Set the column names

3 Add an $\textit{OffsetVar}$ for use in generating the convergence image.

For example, let, $\textit{sampleRepetition} = c(10,20, 30)$. The resulting ${sampleStats}$ data frame will contain three rows. The first will store the mean, variation and error values for the a sample means from a $sampleRepetition = 10$, the second would store the data for a $sampleRepetition = 20$, and the third for a  $sampleRepetition = 30$. 

\textbf{Code Block 3}
\scriptsize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}
calculateSampleMeansStats <- function (sampleRepetition)
{
  sampleStats <- data.frame(N_obs = integer(), mu = double(), muErr = double(),
                            variation = double(), varErr = double())

  for (sample in 1:length(sampleRepetition)) {
    simData       <- generateExponentialData(sampleRepetition[[sample]])
    sampleMeans   <- colMeans(simData)
    xbar          <- mean(sampleMeans)
    sig_2         <- var(sampleMeans)

    sampleStats  <- rbind(sampleStats, c(sampleRepetition[sample], xbar, abs((MU - xbar)/xbar),
                                         sig_2, abs((SAMPLE_VAR - sig_2)/sig_2)))
  }
  colnames(sampleStats) <- c("NRep", "Mean", "Absolute\nError of\nMean",
                             "Variance", "Absolute\nError of\nVariance")
  sampleStats <- cbind(sampleStats, OffsetVar = sampleStats$Variance + 5)
  
  return (sampleStats)
}
```
\normalsize

The sampleStats data frame from function ??? is converted to an image in convergenceImage. The most significant aspects of the function are:

1 ggplot is used to plot $\textit{sampleStats\$Mean}$, $\textit{sampleStats\$Variance}$, and the constants $\mu$, and  $\textit{variance}$.

2 The axis on the left of the plot is the "Mean" axis, the axis on the right of the plot is the Variance axis. 

3 The Variance axis uses the $\textit{sampleStats\$OffsetVar}$ value to shift the $\textit{sampleStats\$Variance}$ value to match the Variance axis.

4 The y-axis, Sample Size, is a log axis. The sample repetitions are $(10, 20, 30, 40, 100, 1000, 10000, 100000, 1000000)$
\newline

\textbf{Code Block 4}
\scriptsize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}
convergenceImage <- function(sampleRepetition)
{
  sampleStats <- calculateSampleMeansStats(sampleRepetition)
  graphTics   <- c(10, 100, 1000, 10000, 100000, 1000000)

  plt <- ggplot(sampleStats, aes(x = as.numeric(NRep))) +
    geom_hline(yintercept = 5, color="#ffd470", linewidth = 0.5) +
    geom_hline(yintercept = 5.625, color="#a5f7a1", linewidth = 0.5) +
    geom_line(aes(y=OffsetVar, color='Variance')) + 
    geom_line(aes(y=Mean, color='Mean')) +
    
    <Additional ggplot2 formatting>

  ggsave(plot = plt, width = 4.0, height = 2.5, dpi = 300, filename = "converge.png")
}

```
\normalsize

### \textbf{Convergence Image}

The image generated by convergenceImage (Figure 2), shows the convergence of the sample means distribution's mean value in orange and mean value of the exponential distribution $\mu = 5.0$ in light orange. Likewise, the sample means' variance is shown in green and the exponential distribution's variance $variance = 0.625$ is shown in light green.


\begin{wrapfigure}{r}{0.4\textwidth}
  \centering
    \includegraphics[width=\linewidth]{converge.png}
\end{wrapfigure}

This plot satisfies two of the requirements for Part I:

1 \textbf{The theoretical mean of the sample means converges to the same mean as the exponential distribution}. As the number of values in the sample means increases, the mean of the sample means approaches the theoretical value predicted by the CLT. The solid orange line osciallates about $\mu$ until $n \approx 1000$, then it rapidly converges to $\mu$.

2 \textbf{The theoretical variance of the sample means converges to the same variance as the exponential distribution}. As the number of values in the sample means increases, the variance of the sample means approaches the theoretical value predicted by the CLT. The solid green line oscillates about population $variance$ until $n \approx 8000$, then it rapidly converges to the population $variance$.

With the first two requirements satisfied, the next section will demonstrate will demonstrate the the third requirement, the sample means distribution approximates $N(\mu, \sigma^2)$.

### \textbf{The sample means distribution approximates $N(\mu, \sigma^2)$}

To demonstrate the sample means distribution approximates $N(\mu, \sigma^2)$, the code will generate a set of four plots showing the histogram and density curve fit to it, the curve $N(\mu, \sigma^2)$ predicted by the CLT, and two lines showing the means of the fitted and theoretical distributions. The plots are based on sample means with 10, 30, 40, and 1000 samples.

To generate the 


\break

\textbf{Code Block 5}
\scriptsize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}
normalDistributionImages <- function(sampleRepetition)
{
  transformToN <- function(sample) {
    (sample - MU)/SAMPLE_ERR + MU
  }

  for (i in 1:length(sampleRepetition)) {
    simData[[i]]   <- generateExponentialData(sampleRepetition[i])
    colData[[i]]   <- colMeans(simData[[i]])
    sampleMeans[[i]] <- data.frame(pdf = c(unlist(lapply(colData[[i]], transformToN))))
    sourceData[[i]]  <- data.frame(pdf = c(unlist(lapply(simData[[i]], transformToN))))

    pltList[[i]] <- ggplot(sampleMeans[[i]], aes(x = pdf)) +
      stat_function(fun = function (x) dnorm(x, mean =  5, sd = 1),
        color = "#00bfb2", fill = "#00bfb2", geom = "area", alpha = 0.8) +
      geom_density(alpha = 0.3, color = "#000000", fill="#000000")  +
      geom_histogram(aes(y = after_stat(density)), breaks = binRange,
                     alpha = 0.2, color = "#505050", linewidth = 0.2) +
      geom_vline(aes(xintercept=mean(pdf)), color="#000000", linewidth = 0.5, linetype = 2) +
      geom_vline(aes(xintercept = MU), color="#00bfb2", linewidth = 0.5, linetype = 2) +
  }

  plt <- ggarrange(pltList[[1]], pltList[[2]], pltList[[3]], pltList[[4]],
          labels = label, ncol = 2, nrow = 2)
  ggsave(plot = plt, width = 6.0, height = 4.0, dpi = 300, filename = "distribution.png")
}

```
\normalsize


\textbf{Code Block 5a}
\scriptsize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}
normalDistributionImages <- function(sampleRepetition)
{
  binRange          <- seq(2.0, 9.0, by = 0.25)
  label <- c("a", "b","c","d")
  pltList <- list()

  transformToN <- function(sample) {
    (sample - MU)/SAMPLE_ERR + MU
  }

  simData  <- list()
  colData  <- list()
  sampleMeans  <- list()
  sourceData  <- list()
  for (i in 1:length(sampleRepetition)) {
    simData[[i]]   <- generateExponentialData(sampleRepetition[i])
    colData[[i]]   <- colMeans(simData[[i]])
  }

  for (i in 1:length(sampleRepetition)) {
    sampleMeans[[i]] <- data.frame(pdf = c(unlist(lapply(colData[[i]], transformToN))))
    sourceData[[i]]  <- data.frame(pdf = c(unlist(lapply(simData[[i]], transformToN))))
  }
```
\normalsize

\textbf{Code Block 5b}
\scriptsize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}

  for (i in 1:length(sampleRepetition)) {
    pltList[[i]] <- ggplot(sampleMeans[[i]], aes(x = pdf)) +
      stat_function(fun = function (x) dnorm(x, mean =  5, sd = 1),
        color = "#00bfb2", fill = "#00bfb2", geom = "area", alpha = 0.8) +
      geom_density(alpha = 0.3, color = "#000000", fill="#000000")  +
      geom_histogram(aes(y = after_stat(density)), breaks = binRange,
                     alpha = 0.2, color = "#505050", linewidth = 0.2) +
      geom_vline(aes(xintercept=mean(pdf)), color="#000000", linewidth = 0.5, linetype = 2) +
      geom_vline(aes(xintercept = MU), color="#00bfb2", linewidth = 0.5, linetype = 2) +
      geom_hline(yintercept=0, color="#000000", linewidth = 0.5) +

      <Additional ggplot2 formatting>

  }

  plt <- ggarrange(pltList[[1]], pltList[[2]], pltList[[3]], pltList[[4]],
          labels = label, ncol = 2, nrow = 2)
  ggsave(plot = plt, width = 6.0, height = 4.0, dpi = 300, filename = "distribution.png")
}
```
\normalsize

\begin{wrapfigure}{r}{0.4\textwidth}
  \centering
    \includegraphics[width=\linewidth]{distribution.png}
\end{wrapfigure}

# ################################################






In this project you will investigate the exponential distribution in R and compare it with the Central Limit Theorem. 



• Simulations: Include English explanations of the simulations you ran, with the accompanying R code. Your explanations should make clear what the R code accomplishes.

### Central Limit Theorem

Given a probability distribution $P$, a set of $n$ random values from $P$ is a $\textbf{sample.}$ The mean value of a sample from $P$ is called the sample mean, which is a random variable from $N(\mu, \sigma^2)$,  $P$ is not necessarily a normal distribution. The values of $\mu$ and $\sigma^2$ are the mean and variance of $P$.

The Central Limit Theorem (CLT) roughly states that as the number of sample means from distribution $P$ increases the sample distribution converges to the normal distribution $N(\mu, \sigma^2)$.^[The CLT "states the following. Let $X_1, X_2, X_3, ..., X_n$ denote a random sample of $n$ independent observations from a population with overall expected value (average) $\mu$ and a finite variance $\sigma^2$, and let $\bar{X_n}$ denote the sample mean of that sample (which is itself a random variable). Then the limit as $n \to \infty$ of the distribution of $\frac {\bar {X_n} - \mu}{\sigma_{\bar X_n}}$, where $\sigma_{\bar X_n} = \sigma/\sqrt{n}$ [@wikipedia]."]. $P$ does not need to be a normal distribution to get the results predicted by the CLT.

### Exponential Distribution

The exponential distribution is defined as $f(x) = \lambda e^{-\lambda x}$ where $\lambda$ is the \textbf{mean event rate}. The mean and variance are $\mu = 1/\lambda$ and $\sigma^2 = 1/\lambda^2$ respectively. The values of $\mu$ and $\sigma^2$ are the values predicted by the CLT for the normal distribution. To show the CLT predictions are valid, the document code will simulate the collection of sample means, then analyze the simulation results. 


### Simulation

The goal of the simulation is to mimic collecting data from an exponential distribution. Code Block 1 shows the code responsible for generating the simulated data. It is designed to create a list of sample means of



VThe user-defined function responsible for generating the random variables is $textbf{\textit{generateExponentialData}}$.  

```{r printTable, echo = FALSE}
resTable
```

\break

Code Block 1
\footnotesize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}
LAMBDA       <- 0.2
SAMPLE_SIZE   <- 40
mu           <- 1/LAMBDA
SIGMA        <- 1/LAMBDA
VARIANCE     <- SIGMA^2
SAMPLE_ERR     <- SIGMA/sqrt(SAMPLE_SIZE)
```
\normalsize

Code Block 2
\footnotesize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}
generateExponentialData <- function(samples) {
  simData <- matrix(rexp(samples*SAMPLE_SIZE, LAMBDA), nrow = SAMPLE_SIZE, ncol = samples)
  return (simData)
}
```
\normalsize


Code Block 3
\footnotesize
\definecolor{shadecolor}{RGB}{242, 255, 255}
```{r echo=TRUE, eval = FALSE}
calculateSampleMeansStats <- function (sampleRepetition)
{
  sampleStats <- data.frame(N_obs = integer(), mu = double(), muErr = double(),
                            variation = double(), varErr = double())

  for (sample in 1:length(sampleRepetition)) {
    simData       <- generateExponentialData(sampleRepetition[[sample]])
    sampleMeans   <- colMeans(simData)
    xbar          <- mean(sampleMeans)
    sig_2         <- var(sampleMeans)

    sampleStats  <- rbind(sampleStats,
                           c(sampleRepetition[sample], xbar, abs((mu - xbar)/xbar),
                             sig_2, abs((SAMPLE_VAR - sig_2)/sig_2)))
  }
  colnames(sampleStats) <- c("NRep", "Mean", "Absolute\nError of\nMean",
                             "Variance", "Absolute\nError of\nVariance")
  sampleStats <- cbind(sampleStats, OffsetVar = sampleStats$Variance + 5)

  return (sampleStats)
}

```
\normalsize






## Simulating an Exponential Distribution

- Sample Mean versus Theoretical Mean: Include figures with titles. In the figures, highlight the means you are comparing. Include text that explains the figures and what is shown on them, and provides appropriate numbers.
    
## Simulating an Exponential Distribution

- Sample Variance versus Theoretical Variance: Include figures (output from R) with titles. Highlight the variances you are comparing. Include text that explains your understanding of the differences of the variances.
    
## Simulating an Exponential Distribution

- Distribution: Via figures and text, explain how one can tell the distribution is approximately normal.




The objective of Part I is to demonstrate the validity of the Central Limit Theorem (CLT). 


The CLT"states the following. Let $X_1, X_2, X_3, ..., X_n$ denote a random sample of $n$ independent observations from a population with overall expected value (average) $\mu$ and a finite variance $\sigma^2$, and let $\bar{X_n}$ denote the sample mean of that sample (which is itself a random variable). Then the limit as $n \to \infty$ of the distribution of $\frac {\bar {X_n} - \mu}{\sigma_{\bar X_n}}$, where $\sigma_{\bar X_n} = \sigma/\sqrt{n}$ [@wikipedia]." In other words, the distribution of sample means will approach $N(0,1)$ as the number of samples increases, regardless of the distribution of the random values.

To demonstrate the validity the CLT, the document code generate two images. The first image is a set of four plots showing the sample mean distribution with sample sizes of 10, 30, 40, and 1000. The second image shows the mean and variance values for sample mean distributions with sample repetitions of 10, 20, 30, 40, 100, 1000, 10000, 100000, and 1000000.

### Generate Sample Means

The first step in the generation of both images is the generation of samples means lists. The $\textbf{\textit{generateSampleMeansLists}}$ function is responsible for the generation of the random values from the exponential mean and converting those values to the sample means list. Given the sample repetitions set $\{10, 30, 40, 1000\}$, the simulation will generate four matrices of sizes $40 \times 10$, $40 \times 30$, $40 \times 40$, and $40 \times 1000$. For each matrix, the function computes the mean of each column and stores the means in a list.

The $\textit{sampleMeansLists}$ contain the cleaned raw data.

### Create Sample Means Distribution Plots

The CLT implies that the sample means distribution is expected to converge to a normal distribution $N(1/\lambda, 1/\lambda^2)$ as the number of repetitions increases. To verify the theorem, the doucment code should compute the absolute difference between each point on the two curves. To do this would require a signifant amount of programming and some math outside of the scope of the course. Therefore, this the exercise, will generate images for repeat values of n = 10, 30, 40, and 1000 and it will report the values of the mean and variance of the sample mean for repeat values of 10, 20, 30, 40, 100, 1000, 10000, 100000, and 1000000. The images will show the convergence of the sample means distribution to the normal mean $N(1/\lambda, 1/\lambda^2)$. The data report will show the convergence of the mean and variance of the sample mean to $1/\lambda$, and $1/\lambda^2$ respectively. 

Both the image and the report rely on the $\textbf{\textit{generateSampleMeansLists}}$ function to create a list of sample means $\textit{sampleMeansLists}$, where each member of the list is a sample means. Each of the sample means is the size of the repetition value used to generate the sample means. In other words, the sample means for a repetition value of ten will have tem elements, the one with a repetition value of forty will have forty elements, etc. (see Appendix I for the specific code).

To create the Sample Means Distribution images, the code processes the $\textit{sampleMeansLists}$ data as follows

- Convert the $\textit{sampleMeansLists}$ data to the standard normal curve using

\begin{equation}
\frac {\bar {X_n} - \mu}{\sigma_{\bar X_n}}
\end{equation}

- Translate the standard normal curve back to its origional location by adding 5.0 to each element of the distribution.

+ After this process, the sample means distribution should be normalized and should have the same mean and variance as the Standard Normal Distribution.

+ By increasing the number of repetitions, the sample means distribution should look like $N(5,1)$.

Figures 1 a-d show the histogram of the sample means, an approximation of the sample means distribution, the normal distribuion $N(5,1)$, a vertical line at the mean of the sample distribution and a second vertical line at the mean of $N(5,1)$. The images correspond to repetition $n = 10$, $n = 30$, $n = 40$, and $n = 1000$, and each images shows how the sample means distribution gets closer to the $N(5, 1)$ as $n$ increases. The two vertical lines move closer together until they overlap at $\mu = 5.0$, further supporting the assertion regarding the CLT.

```{r echo=FALSE, out.width = "75%", fig.align = "center"}
knitr::include_graphics("distribution.png")
```

### Quantitative Comparison of Sample Means and Standard Normal Distributions

The qualitative 

In addition to the qualitative comparison of the two distributions, the document code also produces a table to reporti the convergence of the sample means distribution with the normal distribution. Table 1 shows  




#### ==============



To demonstrate the effect of the CLT on the sample means, the document code generates an image using the $\textbf{\textit{imageNormalDistribution}}$ function. The image consists of four graphs for each of the sample means distributions stored in $\textit{sampleMeansLists}$. Figure 1 (a-d) are the plots for repeat values of n=10, 30, 40, and 1000.

Before the creating the graphs, the document code converts the sample means distribution to a standard normal normal using the z-score transformation (eqn1).

\begin{equation}
\frac {\bar {X_n} - \mu}{\sigma_{\bar X_n}} =  \frac {X_n - 1/\lambda} {\sigma_{40}} =  \frac {\bar {X_n} - 5} {\sigma_{40}}.
\end{equation}

The distribution associated by the transformed sample means should approach a standard normal distribution as the value n increases. To demonstrate the visual similarity between the distributions, it is only necessary to compare the size and shape of both.

Figure 1 a-d compares the distributions by overlaying the $\textcolor{red}sample means distribution in black} and the $\textcolor{red}standard normal distribution in blue}. The graph also includes the histogram created by the corresponding $\textcolor{red}sample means distribution as a set of gray bars} and two dashed lines. $\textcolor{red}{The black line is the mean of the sample means distribution}.

Based on the following observations, the graphs verify that as the number of repetitions increases, the sample means distribution approaches the standard normal distribution. 

1) The area of blue shading and the area of black shading decreases as the number of repetitions increases, 
2) the shape sample means approaches the shape of the standard normal as the number of repetitions increases,
3) the size of the sample means distribution approaches the size of the standard noraml distribution as the number of repetitions increases.





<!-- \begin{wrapfigure}{r}{0.5\textwidth} -->
<!--   \centering -->
<!--     \includegraphics[width=\linewidth]{teeth.png} -->
<!-- \end{wrapfigure} -->

<!-- the central limit theorem (CLT) establishes that, in many situations, for independent and identically distributed random variables, the sampling distribution of the standardized sample mean tends towards the standard normal distribution even if the original variables themselves are not normally distributed., which states, "in many situations, for independent and identically distributed random variables, the sampling distribution of the standardized sample mean tends towards the standard normal distribution even if the original variables themselves are not normally distributed[@scribbr]." -->



<!-- that the mean of a large number of samples taken from a distribution will approximate an normal distribution. The point of this demonstration is to validate the Central Limit Theorem, which says "that the sampling distribution of the mean will always follow a normal distribution when the sample size is sufficiently large [@scribbr]."  -->

In this case the code will select values from an exponential distribution,

\begin{equation}
f(x) = \bigg\{
  \begin{array}{ c l }
    \lambda e^{-\lambda x} & \quad \textrm{if } x \geq 0 \\
    0                 & \quad \textrm{if } x < 0
  \end{array}
\end{equation}

## Exponential Distribution Simulation


## =======================================




Part 1 is an analysis of the CLT using a simulation of a non-Gaussian distribution. Each simulation will consist of $n$ samples, and each sample will consist of forty observation taken from an exponential distribution . The project will run the simulation several times each using a different value of $n$. 

For each sample, the program will record the mean and standard values to construct a distribution of the sample means. If the CLT is correct, then the expected result should be a Gaussian distribution with a mean and standard deviation of the rate constant used in the exponential distribution.

## Simulation description














### Exponential distribution

The $\textbf{Exponential Probability Distribution (EPD)}$ with rate constant $\lambda$ is 

where $\frac{1} {\lambda}$ is the rate constant of the distribution. Based on the Johns Hopkins University Statistical Inference Course Project [@JHU-course] the the mean and standard deviation equal $\frac{1} {\lambda}$. A proof for the mean found in The Book of Statistical Proofs [@bookStatProofs-mean] and the variance in [@bookStatProofs-var], keeping in mind that $var = \sigma^2$.

#### ==============


### Central limit theorem
The $\textbf{Central Limit Theorem (CLT)}$ "establishes that, in many situations, for independent and identically distributed random variables, the sampling distribution of the standardized sample mean tends towards the standard normal distribution even if the original variables themselves are not normally distributed.[@wikipedia]" By applying the CLT to the exponential distribution, the program  will show the accuracy of theorem based on the known values of the distribution. 

The central limit theorem asserts "that the sampling distribution of the mean will always follow a normal distribution when the sample size is sufficiently large. This sampling distribution of the mean isn’t normally distributed because its sample size isn’t sufficiently large.[@scribbr]"

To demonstrate how the Central Limit Theorm (CLT) predicts the distribution and parameters for equation 1. To show this, the simulation will generate forty sets of exponential random numbers for each member of the variable $\textit{SampleSize}$. The simulation will calculate the mean for the forty distributions generated for each sample size.



## Simulation

The simulation is designed to mimic the CLT by generating random values from a exponential distribution with $\lambda = 0.2$. Each selection 

The simulations were run four times with 10, 30, 40, and 1000 repetions for of each sample respectively. The resulting sample means were collected as a list then plotted as a bar graph. In addition to the bar graph, the plot also included a density function plot, a Gaussian density plot with N($1/lambda$, $1/lambda$), and a vertical line at the mean of the sample distrbution. The plots are shown in \@ref{fig:figs}.

The simulation mimics sampling from an exponentially distributed population. Each sample consists of forty values collected by invoking the $\textbf{\textit{rexp}}$ function, and the sample collection is repeated $n$ times. The resulting data set is stored in a matrix, and the distribution of the sample means is found by calculating the mean of each column of the matrix. The collection of sample means is used to generate a $\textit{probability density fuction}$, and to produce the mean and variance of the distribution.

<!-- FIGURE ZZZZ(a-d) show sample distributions with repeat values of 10, 30, 40, and 1000. The distribution data is sorted into contiguous intervals.^[\[2.5, 2.75), \[2.75, 3), \[3, 3.25), \[3.25, 3.5), \[3.5, 3.75), \[3.75, 4), \[4, 4.25), \[4.25, 4.5), \[4.5, 4.75), \[4.75, 5), \[5, 5.25), \[5.25, 5.5), \[5.5, 5.75), \[5.75, 6), \[6, 6.25), \[6.25, 6.5), \[6.5, 6.75), \[6.75, 7), \[7, 7.25), \[7.25, 7.5)] Each value in the sample distribution is binned into on  -->

The simulation mimics the CLT by repeatedly selecting a sample with a fixed number of "observations" from an exponential distribution with $\lambda = 0.2$. The simulations were run four times with 10, 30, 40, and 1000 repetions for of each sample respectively. The resulting sample means were collected as a list then plotted as a bar graph. In addition to the bar graph, the plot also included a density function plot, a Gaussian density plot with N($1/lambda$, $1/lambda$), and a vertical line at the mean of the sample distrbution. The plots are shown in \@ref{fig:figs}.

### Sample distributions

The purpose of this project is two fold. The first is to demonstrate the validity of the Central Limit Theorem (CLT) and second is to apply statistical analysis methods to characterize the R "ToothGrowth" data set [@ToothGrowth]. The CLT asserts that the sampling distribution of the mean will always follow a normal distribution when the sample size is sufficiently large [@scribbr]."

To show how the sample distribution changes with the number of repetitions, the program will process the simulation using a set of repeat values. For example, to show the convergence of the sample mean and variance to the theoretical values, is shown using 


simulations repeats in the set the sample mean and variance use the set {10, 20, 30, 40, 100, 1000, 10000, 100000, 1000000, 10000000} to generate ten pairs of means and variances. The


"The central limit theorem says that the sampling distribution of the mean will always follow a normal distribution when the sample size is sufficiently large. This sampling distribution of the mean isn’t normally distributed because its sample size isn’t sufficiently large.[@scribbr]"


To demonstrate how the Central Limit Theorm (CLT) predicts the distribution and parameters for equation 1. To show this, the simulation will generate forty sets of exponential random numbers for each member of the variable $\textit{SampleSize}$. The simulation will calculate the mean for the forty distributions generated for each sample size.

After calculating the mean and variance for each sample size, the simulation will generate images showing the convergence of both the sample mean and variance as $n \to \infty$. Additionally, the code with generate four plots with $n = 2, 10, 30, 40$ to show the convergence of the sample distribution to a Gaussian distribution. 
The specific steps are:

1. Loop through the $\textit{SampleSize}$ list to get the next sample size, $n$
  + Generate an $n \times nSamples$ matrix and populate it with random variables from the exponential distribution. 
  + Calculate the mean value of each column of the matrix i.e., the sample means, and store the resulting values in the $meanColMatrix$. Each column is a distribution of sample means for a given $n$.
  +  Continue looping
2. Loop through the each column of the $meanColMatrix$
  + Calculate the mean and standard deviation of each column
  + Bind a list with the sample size $n$, and the mean and variance for the $meanColMatrix$ to the $sampleStats$ data frame.
  + Continue looping

## Results













3. Generate Figure 1. This figure is a plot of the sample mean and variance versus the number of samples. The blue line in Figure 1 is the mean of sample mean, and it shows that as $n$ gets larger, it converges the the expected mean $1/\lambda = 5.0$. Figure 1 also represents the change in variance of the sample mean with respect to $n$. The expected variance of the sample distribution

\begin{equation}
Var(X) = \frac{\sigma^2}{n} = \bigg ( \frac {1}{\lambda} \bigg)^2 \frac {1} {n} = 25.0/n,
\end{equation}

(see Appendix 1, section ????).






4. Generate Figure 2. 


Show the sample mean and compare it to the theoretical mean of the distribution.
Show how variable the sample is (via variance) and compare it to the theoretical variance of the distribution.
Show that the distribution is approximately normal.
In point 3, focus on the difference between the distribution of a large collection of random exponentials and the distribution of a large collection of averages of 40 exponentials.





<!-- # Preliminaries -->
<!-- **Exponential Distribution** -->

<!-- The exponential distribution is defined by the function -->

<!-- \[f(x) = \bigg\{ -->
<!--   \begin{array}{ c l } -->
<!--     \lambda e^{-\lambda x} & \quad \textrm{if } x \geq 0 \\ -->
<!--     0                 & \quad \textrm{if } x < 0 -->
<!--   \end{array}\] -->

<!-- where the rate parameter $\lambda$ is the mean number of events over a given time period^[https://en.wikipedia.org/wiki/Exponential_distribution]. The of mean and standard deviations of the exponential distribution are $1/\lambda$ and the variation is $1/\lambda^2$. Derivations for the mean^[https://statproofbook.github.io/P/exp-mean.html] and variance^[https://statproofbook.github.io/P/exp-var.html] can be found in \textbf{The Book of Statistical Proofs}.  -->

**Central Limit Theorem**

<!-- The Central Limit Theorem (CLT) says the mean of sample means of size n will approach the population mean as $n \to \infty$. It also states that the standard deviation of the sample means $\sigma/\sqrt n$ will approach zero as $n \to \infty$ where $\sigma$ is the population mean. It also shows as $n \to \infty$ the sample distribution will approach a normal distribution $N(\mu, \sigma/\sqrt n)$. -->

<!-- # Project 6, part 1: The Exponential Distribution -->
<!-- The goal of this section is to demonstrate the validity of the Central Limit Theorem with respect the exponential distribution. It entails performing several simulations of an exponential distribution to demonstrate the convergence of sample means and the standard error to their theoretical values. It will also display graphical results to visualize the convergence of the distributions to the normal distribution. -->

<!-- The simulation procedure uses the following steps: -->

<!-- 1. Generate a matrix of random values from an exponential distribution. -->
<!--   - The rate constant for the distribution is $\lambda = 0.2$, number of columns in the matrix is 40. -->
<!--   - The number of rows varies in size to show the impact of the CLT. -->
<!-- 2. Store the first row from each matrix, i.e., the first sample distribution in the matrix. -->
<!-- 3. Calculate the mean of each sample in each matrix. This is the sample distribution. -->
<!-- 4. For each sample distribution, store the sample mean and standard deviation. -->

<!-- ### **The Sample Mean and Standard deviation** -->


<!-- \begin{wrapfigure}{r}{0.3\textwidth} -->
<!--   \centering -->
<!--     \includegraphics[width=\linewidth]{converge.png} -->
<!--   \caption{The plot shows the sample mean (blue) and the sample deviation (red). Note the left scale refers to the sample mean and the right refers to the same deviation.} -->
<!-- \end{wrapfigure} -->

<!-- Before the simulation starts, it will create forty sets of samples for each of the specified sample size set^[the sample sizes are: 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 2000, 3000]. It will then create a $n \times 40$ matrix, where $n$ a specified sample size. Each matrix will be filled with random values from an exponential distribution with rate parameter $\lambda$.  -->

<!-- The simulation will compute the average value for each column in each matrix, which results in a column means for the matrix. The column means are then bound to the columns of second matrix called the $meanColMatrix$. Once all of the column means are collected, the $meanColMatrix$ is a $40 \times 21$ matrix, with the full set of column means for each simulation size.  -->

<!-- Based on the exponential distribution, the CLT predicts the column means will converge to $1/\lambda = 1/0.20 = 5.0$ and the standard deviation will converge to 0 as $n \to \infty$. Figure 1 shows the convergence of both the mean and standard deviations. Table 1 includes some select points to show the convergence quantitatively. -->

```{r, echo = FALSE}
  # knitr::kable(statData)
```

<!-- ### *** Normal distribution *** -->
<!-- \begin{wrapfigure}{r}{0.4\textwidth} -->
<!--   \centering -->
<!--     \includegraphics[width=\linewidth]{distribution.png} -->
<!--   \caption{Histograms of } -->
<!-- \end{wrapfigure} -->

<!-- The third requirement for validating the CLT is the distribution of the sample means must be normal. This paper will use visualization to verify that the sample means becomes more normal as $n \to \infty$. Figure 2 shows four sample means distributions of varying sample sizes, each plot is represented as a bar chart. In addition to the sample distribution, each plot includes an overlay of a normal distributon with $\mu = 5.0$ and $\sigma = 5.0$. The overlays are red, with the exception of Figure 2d, which is green to draw attention to the scale change. -->

<!-- Figure 2a shows the sample distribution of $n = 10$. Visually, the plot is left skewed, and has a wide variation.  -->


```{r, echo = FALSE}
  # knitr::kable(histogramData)
```



<!-- Figure 2a is the distribution of the sample means where $n = 10$.   -->


<!-- # Project 6, Part 2: Tooth Length -->

<!-- \begin{wrapfigure}{r}{0.4\textwidth} -->
<!--   \centering -->
<!--     \includegraphics[width=\linewidth]{teeth.png} -->
<!--   \caption{Plot of pressure against temperature} -->
<!-- \end{wrapfigure} -->

<!-- \lipsum[1-3] -->










## #########################


# Bibliography
<!-- https://stackoverflow.com/questions/68372960/how-to-wrap-text-around-charts-in-a-rmarkdown-knit-to-pdf-document -->

[wikipedia https://en.wikipedia.org/wiki/Exponential_distribution]
[mean https://statproofbook.github.io/P/exp-mean.html]
[variance https://statproofbook.github.io/P/exp-var.html]
[reference lecture notes showing mu = 3.5 for rolling dice]
[scribbr https://www.scribbr.com/statistics/central-limit-theorem/]
[JHU-Course https://www.coursera.org/learn/statistical-inference/home/week/1]
[JHU-Project https://www.coursera.org/learn/statistical-inference/peer/3k8j5/statistical-inference-course-project]

[Crampton, E. W. (1947). The growth of the odontoblast of the incisor teeth as a criterion of vitamin C intake of the guinea pig. The Journal of Nutrition, 33(5), 491--504. 10.1093/jn/33.5.491]

# Appendix 1: Code

```
generateSampleMeansLists <- function(sampleRepetition)
{
  # ----------------------------------------------------------------------------------
  simData <- list()
  sampleMeansLists <- list()

  for (i in 1:length(sampleRepetition)) {
    simData[[i]] <- matrix(rexp(sampleRepetition[i]*SAMPLE_SIZE, LAMBDA),
                                   nrow = SAMPLE_SIZE, ncol = sampleRepetition[i])
    sampleMeansLists[[i]]   <- colMeans(simData[[i]])
  }

  # ----------------------------------------------------------------------------------
}
```
<!-- \begin{wrapfigure}{l}{0.5\textwidth} -->
<!--   \centering -->
<!--     \includegraphics[width=\linewidth]{converge.png} -->
<!-- \end{wrapfigure} -->

```

imageNormalDistribution <- function(sampleRepetition, sampleMeansLists, binRange)
{
  label <- c("a", "b","c","d")
  pltList <- list()

  transformToN <- function(sample) {
    (sample - mu)/SAMPLE_ERR + mu
  }

  for (i in 1:length(sampleRepetition)) {
    frame <- data.frame(pdf = c(unlist(lapply(sampleMeansLists[[i]], transformToN))))
    pltList[[i]] <- ggplot(frame, aes(x = pdf)) +
      stat_function(fun = function (x) dnorm(x, mean =  5, sd = 1),
        color = "#00bfb2", fill = "#00bfb2", geom = "area", alpha = 0.8) +
      geom_density(alpha = 0.3, color = "#000000", fill="#000000")  +
      geom_histogram(aes(y = after_stat(density)), breaks = binRange, 
                     alpha = 0.2, color = "#505050", linewidth = 0.2) +
      geom_vline(aes(xintercept=mean(pdf)), color="#000000", linewidth = 0.5, linetype = 2) +
      geom_vline(aes(xintercept = 0.0), color="#00bfb2", linewidth = 0.5, linetype = 2) +
      geom_hline(yintercept=0, color="#000000", linewidth = 0.5) +
      ggtitle(paste0("Sample Mean with n = ", sampleRepetition[i])) +
      scale_x_continuous(limits = c(-5, 10), "Mean") +
      scale_y_continuous(limits = c(-0.1, 1), "Density")
  }

  plt <- ggarrange(pltList[[1]], pltList[[2]], pltList[[3]], pltList[[4]],
          labels = label, ncol = 2, nrow = 2)
  ggsave(plot = plt, width = 6.0, height = 4.0, dpi = 300, filename = "distribution.png")
}
```






# --------------------------------


### Generate Sample Distributions

```{r problem1, echo=FALSE}

# set.seed(101)
# 
# nSamples     <- 40
# LAMBDA       <- 0.2
# mu           <- 1/LAMBDA
# SIGMA        <- 1/LAMBDA
# var          <- 1/LAMBDA^2
# exponentSampleMatrix <- matrix()
# 
# # Simulate 1,000 samples with 40 observations each
# setSource <- function (SAMPLE_SIZE)
# {
#   meanColMatrix          <- matrix(nrow = 0, ncol = nSamples)
#   
#   # print(paste0("sample len ", length(SAMPLE_SIZE)))
#   # print("meanMat data")
#   # print("SAMPLE_SIZE[i]   mu   SIGMA")
# 
#   for (i in 1:length(SAMPLE_SIZE)) {
#     
#         #                                    40
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+  nSamples
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
#         # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
# 
# # MDist   ------------------------------------------------------------------------------> 10z`
# # MDist   ------------------------------------------------------------------------------> 20
# 
#     exponentSampleMatrix <- matrix(rexp(SAMPLE_SIZE[i]*nSamples, LAMBDA), 
#                                    nrow = SAMPLE_SIZE[i], ncol = nSamples)
#           
# 
#     # print("setSource: dims(exponentSampleMatrix)")
#     # print(dim(exponentSampleMatrix))
#     # print("setSource: colMeans(exponentSampleMatrix)")
#     # print(colMeans(exponentSampleMatrix))
#     # print(exponentSampleMatrix)
#     
#     meanColMatrix       <- rbind(meanColMatrix, colMeans(exponentSampleMatrix))
# 
#     filename <- paste0("sampleMatrix", SAMPLE_SIZE[i], ".csv")
#     write.csv(exponentSampleMatrix, filename, row.names=FALSE)
# 
#     filename <- paste0("meanColMatrix", SAMPLE_SIZE[i], ".csv")
#     write.csv(meanColMatrix, filename, row.names=FALSE)
# 
#     mu      <- mean(meanColMatrix[i,])
#     VARIANCE   <- var(meanColMatrix[i,])
#     print(paste0(SAMPLE_SIZE[i], "   ", mu, "   ", VARIANCE))
#   }
# 
#   return (meanColMatrix)
# }
# 

```

### Generate sample stats

```{r generateSampleStats, echo=FALSE}
# 
# generateSampleStats <- function (SAMPLE_SIZE, meanColMatrix)
# {
#   print("generateSampleStats: meanColMatrix")
#   # print(dim(meanColMatrix))
#   # print(meanColMatrix)
# 
#   sampleStats         <- data.frame()
#   for (i in 1:length(SAMPLE_SIZE)) {
#     # print("generateSampleStats: length(meanColMatrix[i,]")
#     # print(length(meanColMatrix[i,]))
#     # print("generateSampleStats: meanColMatrix[i]")
#     # print(meanColMatrix)
#     sampleStats  <-
#       rbind(sampleStats, list(SAMPLE_SIZE[i], mean(meanColMatrix[i,]), var(meanColMatrix[i,])))
#   }
#   colnames(sampleStats) <- c("Size", "Mean", "Variance")
# 
# print("generateSampleStats: sampleStats")
# # print(sampleStats)
# filename <- paste0("sampleStats", SAMPLE_SIZE[i], ".csv")
# write.csv(sampleStats, filename, row.names = FALSE)
# 
#   return (sampleStats)
# }
# SAMPLE_SIZE   <- c(10, 20, 30, 40)
# # SAMPLE_SIZE   <- c(10, 20, 30, 40, 100, 1000, 10000, 100000, 1000000, 10000000)
# meanColMatrix   <- setSource(SAMPLE_SIZE)
# sampleStats  <- generateSampleStats(SAMPLE_SIZE, meanColMatrix)

```

